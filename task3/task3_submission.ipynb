{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import andi\n",
    "import numpy as np\n",
    "import csv as csv\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD\n",
    "from keras import losses, metrics\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import SimpleRNN\n",
    "from keras.layers import LSTM\n",
    "\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Bidirectional\n",
    "from tensorflow.keras.models import load_model\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "from data_split import data_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "trajs_from_files = csv.reader(open('challenge_for_scoring/task3.txt','r'), delimiter=';', \n",
    "                                        lineterminator='\\n',quoting=csv.QUOTE_NONNUMERIC)\n",
    "validation = [[],[],[]]\n",
    "for trajs in enumerate(trajs_from_files):\n",
    "    validation[int(trajs[1][0])-1].append(trajs[1][1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_switch_a_t_new = load_model('task3_new.h5')\n",
    "\n",
    "model_switch_a_t_diff = load_model('diff_task3.h5')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model_classi_first = load_model('task3_classi_first10249.h5')\n",
    "\n",
    "#model_classi_sec = load_model('task3_classi_second.h5')\n",
    "\n",
    "#using new net, NB this requires diff and no time stamp\n",
    "\n",
    "model_classi_sec = load_model('taks_3_classify_second_new.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Personalized arctan to convert predictions into switching times stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_atan(x1,x2):\n",
    "    y=np.arctan2(x1,x2)\n",
    "    b=y<0\n",
    "    c=b.astype(int)*(2*np.pi)\n",
    "    d=y+c \n",
    "    return    d;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for 1d\n",
    "i=200\n",
    "validation1d=validation[0]\n",
    "test_tim_step=np.arange(200)\n",
    "show_time_coll=np.tile(test_tim_step,(len(validation1d),1))\n",
    "data_show,label_show,traj_show,times_show=data_split(np.asarray(validation1d),\n",
    "                                                     show_time_coll,\n",
    "                                                         labels=np.ones(len(validation1d)),\n",
    "                                                         start_row=0,num_row=len(validation1d),\n",
    "                                                         traj_len=np.asarray(validation1d).shape[1],n_in=0,n_samples=1,\n",
    "                                                         p_p=1,hmin=0,hmax=2,limith=False,normalization=True)\n",
    "                                                     \n",
    "# pred_a_t=model_switch_a_t.predict(data_show)\n",
    "# pred_a_t_int=model_switch_a_t_int(data_show)\n",
    "pred_a_t_new=model_switch_a_t_new(data_show)\n",
    "\n",
    "\n",
    "#model classification\n",
    "\n",
    "pred_m1_first=np.argmax(model_classi_first.predict(data_show),axis=1)\n",
    "\n",
    "#pred_m2_sec=np.argmax(model_classi_sec.predict(data_show),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Estimating the exponents and switching point using diff\n",
    "i=200\n",
    "\n",
    "data_show_diff,label_show,traj_show,times_show=data_split(np.diff(np.asarray(validation1d),axis=1),\n",
    "                                                     show_time_coll,\n",
    "                                                         labels=np.ones(len(validation1d)),\n",
    "                                                         start_row=0,num_row=len(validation1d),\n",
    "                                                         traj_len=i-1,n_in=0,n_samples=1,\n",
    "                                                         p_p=1,hmin=0,hmax=2,limith=False,normalization=True)\n",
    "pred_a_t_diff=model_switch_a_t_diff.predict(data_show_diff)\n",
    "pred_m2_sec=np.argmax(model_classi_sec.predict(traj_show.reshape((-1,199,1))),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Estimating the exponents and switching point using the reversed trajectory\n",
    "# i=200\n",
    "\n",
    "# data_show_rev,label_show,traj_show,times_show=data_split(np.fliplr(np.asarray(validation)),\n",
    "#                                                      show_time_coll,\n",
    "#                                                          labels=np.ones(len(validation)),\n",
    "#                                                          start_row=0,num_row=len(validation),\n",
    "#                                                          traj_len=i,n_in=0,n_samples=1,\n",
    "#                                                          p_p=1,hmin=0,hmax=2,limith=False,normalization=True)\n",
    "# pred_a_t_rev=model_switch_a_t_rev.predict(data_show_rev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combining predictions for the switching time\n",
    "# pr_t = my_atan(pred_a_t[:,2],pred_a_t[:,3])*200/(2*np.pi)\n",
    "\n",
    "# pr_t_rev = my_atan(pred_a_t_rev[:,2],pred_a_t_rev[:,3])*200/(2*np.pi)\n",
    "\n",
    "# pr_t_int = my_atan(pred_a_t_int[:,2],pred_a_t_int[:,3])*200/(2*np.pi)\n",
    "\n",
    "pr_t_new = my_atan(pred_a_t_new[:,2],pred_a_t_new[:,3])*200/(2*np.pi)\n",
    "\n",
    "pr_t_diff = my_atan(pred_a_t_diff[:,2],pred_a_t_diff[:,3])*200/(2*np.pi)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pr_t_comb = (pr_t_new+pr_t_diff)/2\n",
    "\n",
    "pred_m1s=pred_m1_first\n",
    "pred_m2s=pred_m2_sec\n",
    "\n",
    "#assembling the total prediction array now giving (t,model 1,a1,model2,a2)\n",
    "predictions=np.zeros((len(validation1d),5))\n",
    "predictions[:,0]=pr_t_comb\n",
    "predictions[:,1]=pred_m1s\n",
    "predictions[:,2]=(pred_a_t_new[:,0]+pred_a_t_diff[:,0])/2\n",
    "predictions[:,3]=pred_m2s\n",
    "predictions[:,4]=(pred_a_t_new[:,1]+pred_a_t_diff[:,1])/2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('task3_predictions1d_new.npy',predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions1d=np.copy(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2d data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for 2d\n",
    "i=200\n",
    "for dim in [2]:\n",
    "    pred_hd_a_t=np.zeros((len(validation[1]),3))\n",
    "    \n",
    "    pred_hd_m1_first=np.zeros((len(validation[1]),5))\n",
    "    pred_hd_m2_sec=np.zeros((len(validation[1]),5))\n",
    "    valid_ch_dim=np.asarray(validation[dim-1])    #validation in the chosen dimension\n",
    "    for jj in range(dim):\n",
    "        x=valid_ch_dim[:,i*jj:i*(jj+1)]\n",
    "        test_tim_step=np.arange(i)\n",
    "        show_time_coll=np.tile(test_tim_step,(len(x),1))\n",
    "        data_show,label_show,traj_show,times_show=data_split(x,\n",
    "                                                             show_time_coll,\n",
    "                                                                 labels=np.ones(len(x)),\n",
    "                                                                 start_row=0,num_row=len(x),\n",
    "                                                                 traj_len=x.shape[1],n_in=0,n_samples=1,\n",
    "                                                                 p_p=1,hmin=0,hmax=2,limith=False,normalization=True)\n",
    "\n",
    "        # pred_a_t=model_switch_a_t.predict(data_show)\n",
    "        # pred_a_t_int=model_switch_a_t_int(data_show)\n",
    "        pred_a_t_new=model_switch_a_t_new(data_show)\n",
    "        pr_t_new = my_atan(pred_a_t_new[:,2],pred_a_t_new[:,3])*200/(2*np.pi)\n",
    "        pred_hd_a_t[:,:2]+=pred_a_t_new[:,:2]/dim\n",
    "        pred_hd_a_t[:,2]+=pr_t_new/dim\n",
    "        #model classification\n",
    "\n",
    "        pred_m1_first=model_classi_first.predict(data_show)\n",
    "        pred_hd_m1_first+=pred_m1_first/dim\n",
    "        \n",
    "        data_show_diff,label_show,traj_show_diff,times_show=data_split(np.diff(x,axis=1),\n",
    "                                                             show_time_coll,\n",
    "                                                                 labels=np.ones(len(x)),\n",
    "                                                                 start_row=0,num_row=len(x),\n",
    "                                                                 traj_len=x.shape[1]-1,n_in=0,n_samples=1,\n",
    "                                                                 p_p=1,hmin=0,hmax=2,limith=False,normalization=True)\n",
    "\n",
    "        \n",
    "        pred_m2_sec=model_classi_sec.predict(traj_show_diff.reshape((-1,199,1)))\n",
    "        pred_hd_m2_sec+=pred_m2_sec/dim\n",
    "        \n",
    "    #combining the different dimensions\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions2d[:,0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions2d=np.zeros((len(validation[0]),5))\n",
    "predictions2d[:,0]=pred_hd_a_t[:,2]  # t switch\n",
    "predictions2d[:,1]=np.argmax(pred_hd_m1_first,axis=1)\n",
    "predictions2d[:,2]=pred_hd_a_t[:,0]  # a1\n",
    "predictions2d[:,3]=np.argmax(pred_hd_m2_sec,axis=1)\n",
    "predictions2d[:,4]=pred_hd_a_t[:,1]  #a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('task3_predictions2d_new.npy',predictions2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for 3d\n",
    "i=200\n",
    "for dim in [3]:\n",
    "    pred_hd_a_t=np.zeros((len(validation[0]),3))\n",
    "    \n",
    "    pred_hd_m1_first=np.zeros((len(validation[0]),5))\n",
    "    pred_hd_m2_sec=np.zeros((len(validation[0]),5))\n",
    "    valid_ch_dim=np.asarray(validation[dim-1])    #validation in the chosen dimension\n",
    "    for jj in range(dim):\n",
    "        x=valid_ch_dim[:,i*jj:i*(jj+1)]\n",
    "        test_tim_step=np.arange(i)\n",
    "        show_time_coll=np.tile(test_tim_step,(len(x),1))\n",
    "        data_show,label_show,traj_show,times_show=data_split(x,\n",
    "                                                             show_time_coll,\n",
    "                                                                 labels=np.ones(len(x)),\n",
    "                                                                 start_row=0,num_row=len(x),\n",
    "                                                                 traj_len=x.shape[1],n_in=0,n_samples=1,\n",
    "                                                                 p_p=1,hmin=0,hmax=2,limith=False,normalization=True)\n",
    "\n",
    "        # pred_a_t=model_switch_a_t.predict(data_show)\n",
    "        # pred_a_t_int=model_switch_a_t_int(data_show)\n",
    "        pred_a_t_new=model_switch_a_t_new(data_show)\n",
    "        pr_t_new = my_atan(pred_a_t_new[:,2],pred_a_t_new[:,3])*200/(2*np.pi)\n",
    "        pred_hd_a_t[:,:2]+=pred_a_t_new[:,:2]/dim\n",
    "        pred_hd_a_t[:,2]+=pr_t_new/dim\n",
    "        #model classification\n",
    "\n",
    "        pred_m1_first=model_classi_first.predict(data_show)\n",
    "        pred_hd_m1_first+=pred_m1_first/dim\n",
    "        \n",
    "        data_show_diff,label_show,traj_show_diff,times_show=data_split(np.diff(x,axis=1),\n",
    "                                                             show_time_coll,\n",
    "                                                                 labels=np.ones(len(x)),\n",
    "                                                                 start_row=0,num_row=len(x),\n",
    "                                                                 traj_len=x.shape[1]-1,n_in=0,n_samples=1,\n",
    "                                                                 p_p=1,hmin=0,hmax=2,limith=False,normalization=True)\n",
    "\n",
    "                \n",
    "        \n",
    "        \n",
    "        pred_m2_sec=model_classi_sec.predict(traj_show_diff.reshape((-1,199,1)))\n",
    "        pred_hd_m2_sec+=pred_m2_sec/dim\n",
    "        \n",
    "predictions3d=np.zeros((len(validation[0]),5))\n",
    "predictions3d[:,0]=pred_hd_a_t[:,2]  # t switch\n",
    "predictions3d[:,1]=np.argmax(pred_hd_m1_first,axis=1)\n",
    "predictions3d[:,2]=pred_hd_a_t[:,0]  # a1\n",
    "predictions3d[:,3]=np.argmax(pred_hd_m2_sec,axis=1)\n",
    "predictions3d[:,4]=pred_hd_a_t[:,1]  #a2    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('task3_predictions3d_new.npy',predictions3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.3000441 , 0.07568342, 0.26319143, 0.04060716, 0.32047388],\n",
       "       [0.06691413, 0.6945819 , 0.20749769, 0.00179599, 0.02921026]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_m1_first[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.23652896, 0.04030416, 0.24889491, 0.08138584, 0.39288618],\n",
       "       [0.09313251, 0.56445937, 0.26713513, 0.00262254, 0.07265043]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_hd_m1_first[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_to_txt2d = 2*np.ones((len(predictions2d), 6))\n",
    "for i in range(len(predictions2d)):\n",
    "    for j in range(5):\n",
    "        \n",
    "        pred_to_txt2d[i, j+1] = predictions2d[i][j]\n",
    "pred_to_txt = np.concatenate((pred_to_txt1d,pred_to_txt2d))\n",
    "np.savetxt('task3_tem2d.txt', pred_to_txt.astype(float), fmt = '%1.5f', delimiter = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pred_to_txt1d=np.genfromtxt('task3.txt', delimiter = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_to_txt3d = 3*np.ones((len(predictions3d), 6))\n",
    "for i in range(len(predictions3d)):\n",
    "    for j in range(5):\n",
    "        \n",
    "        pred_to_txt3d[i, j+1] = predictions3d[i][j]\n",
    "pred_to_txt_fin = np.concatenate((pred_to_txt,pred_to_txt3d))\n",
    "np.savetxt('task3_tem3d.txt', pred_to_txt_fin.astype(float), fmt = '%1.5f', delimiter = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 5)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions3d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 5)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions2d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 5)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions1d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
