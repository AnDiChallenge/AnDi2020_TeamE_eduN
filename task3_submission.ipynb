{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import andi\n",
    "import numpy as np\n",
    "import csv as csv\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD\n",
    "from keras import losses, metrics\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import SimpleRNN\n",
    "from keras.layers import LSTM\n",
    "\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Bidirectional\n",
    "from tensorflow.keras.models import load_model\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "from data_split import data_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "trajs_from_files = csv.reader(open('challenge_for_scoring/task3.txt','r'), delimiter=';', \n",
    "                                        lineterminator='\\n',quoting=csv.QUOTE_NONNUMERIC)\n",
    "validation = [[],[],[]]\n",
    "for trajs in enumerate(trajs_from_files):\n",
    "    validation[int(trajs[1][0])-1].append(trajs[1][1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the networks, two (three) for inference of exponents and switching times, one for classification of first model, one for classification of second model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_switch_a_t_new = load_model('nets/task3/1d/task3_new.h5')\n",
    "\n",
    "model_switch_a_t_diff = load_model('nets/task3/1d/diff_task3.h5')\n",
    "\n",
    "#model_switch_a_t_diff_new = load_model('nets/task3/taks_3_inference_200_new.h5')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model_classi_first = load_model('nets/task3/1d/taks_3_classify_frst_checkout200.h5')\n",
    "\n",
    "#model_classi_sec = load_model('task3_classi_second.h5')\n",
    "\n",
    "#using new net, NB this requires diff and no time stamp\n",
    "\n",
    "model_classi_sec = load_model('nets/task3/1d/taks_3_classify_second_checkout200.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Personalized arctan to convert predictions into switching times stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_atan(x1,x2):\n",
    "    y=np.arctan2(x1,x2)\n",
    "    b=y<0\n",
    "    c=b.astype(int)*(2*np.pi)\n",
    "    d=y+c \n",
    "    return    d;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1d case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the model works using the positions as inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for 1d\n",
    "i=200\n",
    "validation1d=validation[0]\n",
    "test_tim_step=np.arange(200)\n",
    "show_time_coll=np.tile(test_tim_step,(len(validation1d),1))\n",
    "data_show,label_show,traj_show,times_show=data_split(np.asarray(validation1d),\n",
    "                                                     show_time_coll,\n",
    "                                                         labels=np.ones(len(validation1d)),\n",
    "                                                         start_row=0,num_row=len(validation1d),\n",
    "                                                         traj_len=np.asarray(validation1d).shape[1],n_in=0,n_samples=1,\n",
    "                                                         p_p=1,hmin=0,hmax=2,limith=False,normalization=True)\n",
    "                                                     \n",
    "# pred_a_t=model_switch_a_t.predict(data_show)\n",
    "# pred_a_t_int=model_switch_a_t_int(data_show)\n",
    "pred_a_t_new=model_switch_a_t_new(data_show)\n",
    "\n",
    "\n",
    "#model classification\n",
    "\n",
    "#pred_m1_first=np.argmax(model_classi_first.predict(data_show),axis=1)\n",
    "\n",
    "#pred_m2_sec=np.argmax(model_classi_sec.predict(data_show),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The other models take the increments as inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Estimating the exponents and switching point using diff\n",
    "i=200\n",
    "\n",
    "data_show_diff,label_show,traj_show,times_show=data_split(np.diff(np.asarray(validation1d),axis=1),\n",
    "                                                     show_time_coll,\n",
    "                                                         labels=np.ones(len(validation1d)),\n",
    "                                                         start_row=0,num_row=len(validation1d),\n",
    "                                                         traj_len=i-1,n_in=0,n_samples=1,\n",
    "                                                         p_p=1,hmin=0,hmax=2,limith=False,normalization=True)\n",
    "\n",
    "pred_a_t_diff=model_switch_a_t_diff.predict(data_show_diff)\n",
    "\n",
    "#pred_a_t_diff_new=model_switch_a_t_diff_new.predict(data_show_diff)\n",
    "\n",
    "\n",
    "pred_m1_first=np.argmax(model_classi_first.predict(data_show_diff),axis=1)\n",
    "\n",
    "pred_m2_sec=np.argmax(model_classi_sec.predict(data_show_diff),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predictions for the switching times are made by taking the average of the 3 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combining predictions for the switching time\n",
    "# pr_t = my_atan(pred_a_t[:,2],pred_a_t[:,3])*200/(2*np.pi)\n",
    "\n",
    "# pr_t_rev = my_atan(pred_a_t_rev[:,2],pred_a_t_rev[:,3])*200/(2*np.pi)\n",
    "\n",
    "# pr_t_int = my_atan(pred_a_t_int[:,2],pred_a_t_int[:,3])*200/(2*np.pi)\n",
    "\n",
    "pr_t_new = my_atan(pred_a_t_new[:,2],pred_a_t_new[:,3])*200/(2*np.pi)\n",
    "\n",
    "pr_t_diff = my_atan(pred_a_t_diff[:,2],pred_a_t_diff[:,3])*200/(2*np.pi)\n",
    "\n",
    "\n",
    "#pr_t_diff_new = my_atan(pred_a_t_diff_new[:,2],pred_a_t_diff_new[:,3])*200/(2*np.pi)\n",
    "\n",
    "pr_t_comb = (pr_t_new+pr_t_diff)/2.\n",
    "\n",
    "#pr_t_comb = (pr_t_new+pr_t_diff+pr_t_diff_new)/3\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Renaming the classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_m1s=np.copy(pred_m1_first)\n",
    "pred_m2s=np.copy(pred_m2_sec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assembling the total prediction array  in the format required by submission, giving (t,model 1,a1,model2,a2). t is obtained avearging 2 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "predictions1d=np.zeros((len(validation1d),5))\n",
    "predictions1d[:,0]=pr_t_comb\n",
    "predictions1d[:,1]=pred_m1s\n",
    "predictions1d[:,2]=(pred_a_t_new[:,0]+pred_a_t_diff[:,0])/2\n",
    "predictions1d[:,3]=pred_m2s\n",
    "predictions1d[:,4]=(pred_a_t_new[:,1]+pred_a_t_diff[:,1])/2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('predictions/task3/task3_predictions1d_final.npy',predictions1d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions1d=np.copy(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_to_txt1d = 1*np.ones((len(predictions1d), 6))\n",
    "for i in range(len(predictions1d)):\n",
    "    for j in range(5):\n",
    "        \n",
    "        pred_to_txt1d[i, j+1] = predictions1d[i][j]\n",
    "pred_to_txt = pred_to_txt1d\n",
    "np.savetxt('task3_tem1d_new.txt', pred_to_txt.astype(float), fmt = '%1.5f', delimiter = ';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2d data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For model detection it is obtained by applying the 1d classifier and averging all dimension independently, we know this may not work well for LW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=200\n",
    "for dim in [2]:\n",
    "#     pred_hd_a_t=np.zeros((len(validation[1]),3))\n",
    "    \n",
    "    pred_hd_m1_first=np.zeros((len(validation[1]),5))\n",
    "    pred_hd_m2_sec=np.zeros((len(validation[1]),5))\n",
    "    valid_ch_dim=np.asarray(validation[dim-1])    #validation in the chosen dimension\n",
    "    for jj in range(dim):\n",
    "        x=valid_ch_dim[:,i*jj:i*(jj+1)]\n",
    "        test_tim_step=np.arange(i)\n",
    "        show_time_coll=np.tile(test_tim_step,(len(x),1))\n",
    "#         data_show,label_show,traj_show,times_show=data_split(x,\n",
    "#                                                              show_time_coll,\n",
    "#                                                                  labels=np.ones(len(x)),\n",
    "#                                                                  start_row=0,num_row=len(x),\n",
    "#                                                                  traj_len=x.shape[1],n_in=0,n_samples=1,\n",
    "#                                                                  p_p=1,hmin=0,hmax=2,limith=False,normalization=True)\n",
    "\n",
    "#         # pred_a_t=model_switch_a_t.predict(data_show)\n",
    "#         # pred_a_t_int=model_switch_a_t_int(data_show)\n",
    "#         pred_a_t_new=model_switch_a_t_new(data_show)\n",
    "#         pr_t_new = my_atan(pred_a_t_new[:,2],pred_a_t_new[:,3])*200/(2*np.pi)\n",
    "#         pred_hd_a_t[:,:2]+=pred_a_t_new[:,:2]/dim\n",
    "#         pred_hd_a_t[:,2]+=pr_t_new/dim\n",
    "        #model classification uses increments\n",
    "\n",
    "        \n",
    "        data_show_diff,label_show,traj_show_diff,times_show=data_split(np.diff(x,axis=1),\n",
    "                                                             show_time_coll,\n",
    "                                                                 labels=np.ones(len(x)),\n",
    "                                                                 start_row=0,num_row=len(x),\n",
    "                                                                 traj_len=x.shape[1]-1,n_in=0,n_samples=1,\n",
    "                                                                 p_p=1,hmin=0,hmax=2,limith=False,normalization=True)\n",
    "\n",
    "        #first model\n",
    "        pred_m1_first=model_classi_first.predict(data_show_diff)\n",
    "        pred_hd_m1_first+=pred_m1_first/dim\n",
    "        \n",
    "        \n",
    "        #second model\n",
    "\n",
    "        pred_m2_sec=model_classi_sec.predict(data_show_diff)\n",
    "        pred_hd_m2_sec+=pred_m2_sec/dim\n",
    "        \n",
    "    #combining the different dimensions\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using net trained on 2d data for inference of a1 , a2 and t_switch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_a_t2d = tf.keras.models.load_model('nets/task3/2d/taks_3_2d_inference_200.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to prepare the data in the right format and normalize it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_prepare_task3_inf(X,dim):\n",
    "    import numpy as np \n",
    "    thr=1e-10\n",
    "    X=np.asarray(X)\n",
    "    print(X.shape)\n",
    "    N=len(X)\n",
    "    #compute length of each trajectory\n",
    "    trj_len=int(X.shape[1]/dim)\n",
    "    xvec=np.zeros((N,trj_len-1,dim+1))\n",
    "    for d in range(dim):\n",
    "        x = np.array(X[:,d*trj_len:(d+1)*trj_len])\n",
    "        x = np.diff(x,axis=1) \n",
    "        sx = np.std(x,axis=1)\n",
    "        xvec[:,:,d] = (x-np.mean(x,axis=1).reshape(len(x),1)) / np.where(sx>thr,sx,1).reshape(len(x),1)   # normalize x data\n",
    "    xvec[:,:,dim]=np.arange(trj_len-1)/trj_len\n",
    "    # regularize labels\n",
    "    \n",
    "    return xvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 400)\n"
     ]
    }
   ],
   "source": [
    "x2d = data_prepare_task3_inf(validation[1],dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 199, 3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred2d_u2d = model_a_t2d.predict(x2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_t_2d_u2d =  my_atan(pred2d_u2d[:,2],pred2d_u2d[:,3])*200/(2*np.pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 4)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred2d_u2d.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assembling the total prediction array  in the format required by submission, giving (t,model 1,a1,model2,a2). For inference, only model new is used and its predictions are averaged in the different dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions2d=np.zeros((len(validation[1]),5))\n",
    "predictions2d[:,0]=pr_t_2d_u2d # t switch\n",
    "predictions2d[:,1]=np.argmax(pred_hd_m1_first,axis=1)\n",
    "predictions2d[:,2]=pred2d_u2d[:,0]  # a1\n",
    "predictions2d[:,3]=np.argmax(pred_hd_m2_sec,axis=1)\n",
    "predictions2d[:,4]=pred2d_u2d[:,1]  #a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('predictions/task3/task3_predictions2d_final.npy',predictions2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_to_txt2d = 2*np.ones((len(predictions2d), 6))\n",
    "for i in range(len(predictions2d)):\n",
    "    for j in range(5):\n",
    "        \n",
    "        pred_to_txt2d[i, j+1] = predictions2d[i][j]\n",
    "pred_to_txt = np.concatenate((pred_to_txt1d,pred_to_txt2d))\n",
    "np.savetxt('task3_tem2d.txt', pred_to_txt.astype(float), fmt = '%1.5f', delimiter = ';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3d data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for 3d\n",
    "i=200\n",
    "for dim in [3]:\n",
    "    #pred_hd_a_t=np.zeros((len(validation[0]),3))\n",
    "    \n",
    "    pred_hd_m1_first=np.zeros((len(validation[0]),5))\n",
    "    pred_hd_m2_sec=np.zeros((len(validation[0]),5))\n",
    "    valid_ch_dim=np.asarray(validation[dim-1])    #validation in the chosen dimension\n",
    "    for jj in range(dim):\n",
    "        x=valid_ch_dim[:,i*jj:i*(jj+1)]\n",
    "        test_tim_step=np.arange(i)\n",
    "        show_time_coll=np.tile(test_tim_step,(len(x),1))\n",
    "#         data_show,label_show,traj_show,times_show=data_split(x,\n",
    "#                                                              show_time_coll,\n",
    "#                                                                  labels=np.ones(len(x)),\n",
    "#                                                                  start_row=0,num_row=len(x),\n",
    "#                                                                  traj_len=x.shape[1],n_in=0,n_samples=1,\n",
    "#                                                                  p_p=1,hmin=0,hmax=2,limith=False,normalization=True)\n",
    "\n",
    "#         # pred_a_t=model_switch_a_t.predict(data_show)\n",
    "#         # pred_a_t_int=model_switch_a_t_int(data_show)\n",
    "#         pred_a_t_new=model_switch_a_t_new(data_show)\n",
    "#         pr_t_new = my_atan(pred_a_t_new[:,2],pred_a_t_new[:,3])*200/(2*np.pi)\n",
    "#         pred_hd_a_t[:,:2]+=pred_a_t_new[:,:2]/dim\n",
    "#         pred_hd_a_t[:,2]+=pr_t_new/dim\n",
    "        \n",
    "#         #model classification\n",
    "\n",
    "       \n",
    "        data_show_diff,label_show,traj_show_diff,times_show=data_split(np.diff(x,axis=1),\n",
    "                                                             show_time_coll,\n",
    "                                                                 labels=np.ones(len(x)),\n",
    "                                                                 start_row=0,num_row=len(x),\n",
    "                                                                 traj_len=x.shape[1]-1,n_in=0,n_samples=1,\n",
    "                                                                 p_p=1,hmin=0,hmax=2,limith=False,normalization=True)\n",
    "\n",
    "        #first model\n",
    "        pred_m1_first=model_classi_first.predict(data_show_diff)\n",
    "        pred_hd_m1_first+=pred_m1_first/dim\n",
    "        \n",
    "        \n",
    "        #second model\n",
    "\n",
    "        pred_m2_sec=model_classi_sec.predict(data_show_diff)\n",
    "        pred_hd_m2_sec+=pred_m2_sec/dim\n",
    "                        \n",
    "        \n",
    "        \n",
    "#         pred_m2_sec=model_classi_sec.predict(traj_show_diff.reshape((-1,199,1)))\n",
    "#         pred_hd_m2_sec+=pred_m2_sec/dim\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the net trained on 2d data on 2d projections of the the 3d data and taking the average:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x3d = data_prepare_task3_inf(validation[2],3)\n",
    "prede3d_vec=[]\n",
    "rr=np.arange(0,4)\n",
    "#print(rr)\n",
    "for i in range(3):\n",
    "   # print(i)\n",
    "    aind=rr!=i\n",
    "\n",
    "\n",
    "    prede3d_vec.append(model_a_t2d.predict(x3d[:,:,aind]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking the averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred3d_u2d = np.zeros((len(validation[2]),3))\n",
    "for i in range(3):\n",
    "    pred3d_u2d[:,:2]+=prede3d_vec[i][:,:2]/3\n",
    "    pr_t_new = my_atan(prede3d_vec[i][:,2],prede3d_vec[i][:,3])*200/(2*np.pi)\n",
    "\n",
    "    pred3d_u2d[:,2]+=pr_t_new/3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assembling the total prediction array  in the format required by submission, giving (t,model 1,a1,model2,a2). For inference, only model new is used and its predictions are averaged in the different dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions3d=np.zeros((len(validation[0]),5))\n",
    "predictions3d[:,0]=pred3d_u2d[:,2]  # t switch\n",
    "predictions3d[:,1]=np.argmax(pred_hd_m1_first,axis=1)\n",
    "predictions3d[:,2]=pred3d_u2d[:,0]  # a1\n",
    "predictions3d[:,3]=np.argmax(pred_hd_m2_sec,axis=1)\n",
    "predictions3d[:,4]=pred3d_u2d[:,1]  #a2    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('predictions/task3/task3_predictions3d_final.npy',predictions3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_m1_first[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_hd_m1_first[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pred_to_txt1d=np.genfromtxt('task3.txt', delimiter = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_to_txt3d = 3*np.ones((len(predictions3d), 6))\n",
    "for i in range(len(predictions3d)):\n",
    "    for j in range(5):\n",
    "        \n",
    "        pred_to_txt3d[i, j+1] = predictions3d[i][j]\n",
    "pred_to_txt_fin = np.concatenate((pred_to_txt,pred_to_txt3d))\n",
    "np.savetxt('task3_tem3d_new.txt', pred_to_txt_fin.astype(float), fmt = '%1.5f', delimiter = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions3d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions2d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions1d.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
