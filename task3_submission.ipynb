{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import andi\n",
    "import numpy as np\n",
    "import csv as csv\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD\n",
    "from keras import losses, metrics\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import SimpleRNN\n",
    "from keras.layers import LSTM\n",
    "\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Bidirectional\n",
    "from tensorflow.keras.models import load_model\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "from data_split import data_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Conv1D, Dropout, BatchNormalization, Flatten\n",
    "\n",
    "from keras.regularizers import l2 as regularizer_l2\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "#from keras.utlils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AD = andi.andi_datasets()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "trajs_from_files = csv.reader(open('validation_for_scoring/task3.txt','r'), delimiter=';', \n",
    "                                        lineterminator='\\n',quoting=csv.QUOTE_NONNUMERIC)\n",
    "validation = [[],[],[]]\n",
    "for trajs in enumerate(trajs_from_files):\n",
    "    validation[int(trajs[1][0])-1].append(trajs[1][1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_switch_a_t = load_model('task3_a_t.h5')\n",
    "\n",
    "# model_switch_a_t_rev = load_model('task3_a_t_rev.h5')\n",
    "\n",
    "#model_switch_a_t_ = tf.keras.models.load_model('task3_int.h5')\n",
    "\n",
    "model_switch_a_t_new = load_model('task3_new.h5')\n",
    "\n",
    "model_switch_a_t_diff = load_model('diff_task3.h5')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model_classi_first = load_model('task3_classi_first10249.h5')\n",
    "\n",
    "model_classi_sec = load_model('task3_classi_second.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Personalized arctan to convert predcitions into switching times stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_atan(x1,x2):\n",
    "    y=np.arctan2(x1,x2)\n",
    "    b=y<0\n",
    "    c=b.astype(int)*(2*np.pi)\n",
    "    d=y+c \n",
    "    return    d;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for 1d\n",
    "i=200\n",
    "validation=validation[0]\n",
    "test_tim_step=np.arange(200)\n",
    "show_time_coll=np.tile(test_tim_step,(len(validation),1))\n",
    "data_show,label_show,traj_show,times_show=data_split(np.asarray(validation),\n",
    "                                                     show_time_coll,\n",
    "                                                         labels=np.ones(len(validation)),\n",
    "                                                         start_row=0,num_row=len(validation),\n",
    "                                                         traj_len=np.asarray(validation).shape[1],n_in=0,n_samples=1,\n",
    "                                                         p_p=1,hmin=0,hmax=2,limith=False,normalization=True)\n",
    "                                                     \n",
    "# pred_a_t=model_switch_a_t.predict(data_show)\n",
    "# pred_a_t_int=model_switch_a_t_int(data_show)\n",
    "pred_a_t_new=model_switch_a_t_new(data_show)\n",
    "\n",
    "\n",
    "#model classification\n",
    "\n",
    "pred_m1_first=np.argmax(model_classi_first.predict(data_show),axis=1)\n",
    "pred_m2_sec=np.argmax(model_classi_sec.predict(data_show),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.diff(np.asarray(validation)[:2,:10],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.asarray(validation)[:2,:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Estimating the exponents and switching point using diff\n",
    "i=200\n",
    "\n",
    "data_show_diff,label_show,traj_show,times_show=data_split(np.diff(np.asarray(validation),axis=1),\n",
    "                                                     show_time_coll,\n",
    "                                                         labels=np.ones(len(validation)),\n",
    "                                                         start_row=0,num_row=len(validation),\n",
    "                                                         traj_len=i-1,n_in=0,n_samples=1,\n",
    "                                                         p_p=1,hmin=0,hmax=2,limith=False,normalization=True)\n",
    "pred_a_t_diff=model_switch_a_t_diff.predict(data_show_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Estimating the exponents and switching point using the reversed trajectory\n",
    "i=200\n",
    "\n",
    "data_show_rev,label_show,traj_show,times_show=data_split(np.fliplr(np.asarray(validation)),\n",
    "                                                     show_time_coll,\n",
    "                                                         labels=np.ones(len(validation)),\n",
    "                                                         start_row=0,num_row=len(validation),\n",
    "                                                         traj_len=i,n_in=0,n_samples=1,\n",
    "                                                         p_p=1,hmin=0,hmax=2,limith=False,normalization=True)\n",
    "pred_a_t_rev=model_switch_a_t_rev.predict(data_show_rev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.abs(pred_a_t_int[:,0]-pred_a_t_new[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.abs(pred_a_t_int[:,0]-pred_a_t[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combining predictions for the switching time\n",
    "# pr_t = my_atan(pred_a_t[:,2],pred_a_t[:,3])*200/(2*np.pi)\n",
    "\n",
    "# pr_t_rev = my_atan(pred_a_t_rev[:,2],pred_a_t_rev[:,3])*200/(2*np.pi)\n",
    "\n",
    "# pr_t_int = my_atan(pred_a_t_int[:,2],pred_a_t_int[:,3])*200/(2*np.pi)\n",
    "\n",
    "pr_t_new = my_atan(pred_a_t_new[:,2],pred_a_t_new[:,3])*200/(2*np.pi)\n",
    "\n",
    "pr_t_diff = my_atan(pred_a_t_diff[:,2],pred_a_t_diff[:,3])*200/(2*np.pi)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pr_t_comb = (pr_t_new+pr_t_diff)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_m1s=pred_m1_first\n",
    "pred_m2s=pred_m2_sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assembling the total prediction array now giving (t,model 1,a1,model2,a2)\n",
    "predictions=np.zeros((len(validation),5))\n",
    "predictions[:,0]=pr_t_comb\n",
    "predictions[:,1]=pred_m1s\n",
    "predictions[:,2]=(pred_a_t_new[:,0]+pred_a_t_diff[:,0])/2\n",
    "predictions[:,3]=pred_m2s\n",
    "predictions[:,4]=(pred_a_t_new[:,1]+pred_a_t_diff[:,1])/2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_to_txt = np.ones((len(predictions), 6))\n",
    "for i in range(len(predictions)):\n",
    "    for j in range(5):\n",
    "        \n",
    "        pred_to_txt[i, j+1] = predictions[i][j]\n",
    "\n",
    "np.savetxt('task3.txt', pred_to_txt.astype(float), fmt = '%1.5f', delimiter = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
