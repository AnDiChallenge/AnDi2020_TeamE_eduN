{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import andi\n",
    "import numpy as np\n",
    "import csv as csv\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD\n",
    "from keras import losses, metrics\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import SimpleRNN\n",
    "from keras.layers import LSTM\n",
    "\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Bidirectional\n",
    "from keras.models import load_model\n",
    "import os\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Conv1D, Dropout, BatchNormalization, Flatten\n",
    "\n",
    "from keras.regularizers import l2 as regularizer_l2\n",
    "\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "AD = andi.andi_datasets()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Important to create a \"balanced\" data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a dataset for task(s) 2 and dimension(s) 1.\n",
      "Generating dataset for dimension 1.\n",
      "Creating a dataset for task(s) 2 and dimension(s) 1.\n",
      "Generating dataset for dimension 1.\n",
      "Creating a dataset for task(s) 2 and dimension(s) 1.\n",
      "Generating dataset for dimension 1.\n",
      "Creating a dataset for task(s) 2 and dimension(s) 1.\n",
      "Generating dataset for dimension 1.\n",
      "Creating a dataset for task(s) 2 and dimension(s) 1.\n",
      "Generating dataset for dimension 1.\n",
      "Creating a dataset for task(s) 2 and dimension(s) 1.\n",
      "Generating dataset for dimension 1.\n",
      "Creating a dataset for task(s) 2 and dimension(s) 1.\n",
      "Generating dataset for dimension 1.\n",
      "Creating a dataset for task(s) 2 and dimension(s) 1.\n",
      "Generating dataset for dimension 1.\n",
      "Creating a dataset for task(s) 2 and dimension(s) 1.\n",
      "Generating dataset for dimension 1.\n",
      "Creating a dataset for task(s) 2 and dimension(s) 1.\n",
      "Generating dataset for dimension 1.\n"
     ]
    }
   ],
   "source": [
    "bb={}\n",
    "cc={}\n",
    "cl=25+100*np.arange(10)\n",
    "j=0\n",
    "for i in cl:\n",
    "    X1, Y1, X2, Y2, X3, Y3 = AD.andi_dataset(N = 10000, tasks = 2, dimensions = 1,\n",
    "                                             min_T = i, max_T = i+1, save_dataset=True, path_datasets=str(i)+'multi')\n",
    "    bb[i]=X2[0]\n",
    "    cc[i]=Y2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a dataset for task(s) 2 and dimension(s) 1.\n",
      "Creating a dataset for task(s) 2 and dimension(s) 1.\n",
      "Creating a dataset for task(s) 2 and dimension(s) 1.\n",
      "Creating a dataset for task(s) 2 and dimension(s) 1.\n",
      "Creating a dataset for task(s) 2 and dimension(s) 1.\n",
      "Creating a dataset for task(s) 2 and dimension(s) 1.\n",
      "Creating a dataset for task(s) 2 and dimension(s) 1.\n",
      "Creating a dataset for task(s) 2 and dimension(s) 1.\n",
      "Creating a dataset for task(s) 2 and dimension(s) 1.\n",
      "Creating a dataset for task(s) 2 and dimension(s) 1.\n"
     ]
    }
   ],
   "source": [
    "bbv={}\n",
    "ccv={}\n",
    "cl=25+100*np.arange(10)\n",
    "j=0\n",
    "for i in cl:\n",
    "    X1, Y1, X2, Y2, X3, Y3 = AD.andi_dataset(N = 1000, tasks = 2, dimensions = 1,\n",
    "                                             min_T = i, max_T = i+1, load_dataset=True, path_datasets=str(i)+'multi_val')\n",
    "    bbv[i]=X2[0]\n",
    "    ccv[i]=Y2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccm={}\n",
    "for i in cl:\n",
    "    ccm[i]=np.zeros((len(cc[i]),5))\n",
    "    print(ccm[i])\n",
    "    print(ccm[i][j][2])\n",
    "    for j in range(len(cc[i])):\n",
    "        ccm[i][j][int(cc[i][j])]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "0.0\n",
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "0.0\n",
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "0.0\n",
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "0.0\n",
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "0.0\n",
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "0.0\n",
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "0.0\n",
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "0.0\n",
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "0.0\n",
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "ccvm={}\n",
    "for i in cl:\n",
    "    ccvm[i]=np.zeros((len(ccv[i]),5))\n",
    "    print(ccvm[i])\n",
    "    print(ccvm[i][j][2])\n",
    "    for j in range(len(ccv[i])):\n",
    "        ccvm[i][j][int(ccv[i][j])]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FUNCTION TO TURN SPLIT DATA IN NORMALIZED SUB-TRAJECTORIES.\n",
    "#Possible to choose data corresponding to a certain interval of h\n",
    "#USING TIMES TOO Otpion to normalize!!\n",
    "#Should find a more elegant way of using the hmin and hmax, now i have to express it anyway\n",
    "def data_split(data_tot,meas_times,labels,start_row,num_row,traj_len,\n",
    "               n_in,n_samples,hmin=0.,hmax=1,limith=False,normalization=True,p_p=1):\n",
    "    '''\n",
    "    returns data_tot: collection of recorded trajectories and associated time stamps,\n",
    "    split into normalized sub-trajectories. It also returns the associated labels, and\n",
    "    separately the time stamps and trajectories.\n",
    "    PARAMETERS EXPLANATION:\n",
    "    meas_times: times at which the position was recorded,\n",
    "    labels: the true exponent corresponding with which the trajectory was generated\n",
    "    start_row: exclude recorded trajectories with index i<start_row\n",
    "    num_row: number of recorde trajectories to use (NB the actual number\n",
    "    will be <total number-start_row) \n",
    "    traj_len: length of the trajectory segments to output\n",
    "    n_in: starting data point from the recorded data\n",
    "    n_samples: number of the trajectory segments to take from each recorded trajectory\n",
    "    h_min: use only trajectories genearted with h>h_min\n",
    "    h_max: use only trajectories genearted with h<h_max\n",
    "    p_p: factor introduced to roughly normalize the time steps so that the total trajectory\n",
    "    duration is close to 1'''\n",
    "    j=0\n",
    "\n",
    "\n",
    "\n",
    "    tr=data_tot[start_row:num_row+start_row]\n",
    "    sel_times=meas_times[start_row:num_row+start_row]\n",
    "    tar=labels[start_row:num_row+start_row]\n",
    "\n",
    "    if(limith==True):\n",
    "        \n",
    "        tr=tr[np.where((tar<=hmax) & (tar >=hmin))]\n",
    "        sel_times=sel_times[np.where((tar<=hmax) & (tar >=hmin))]\n",
    "        tar=tar[((tar<=hmax) & (tar >=hmin))]\n",
    "\n",
    "    if(n_samples>1):\n",
    "        \n",
    "        gap=int((data_tot.shape[1]-n_in-traj_len)/(n_samples-1))\n",
    "    else:\n",
    "        gap=0    \n",
    "    print(\"n initial=\",n_in,\"gap=\",gap)\n",
    "    if(gap<traj_len):\n",
    "        print(\"warning!! Overlapping trajectories. gap=\",\n",
    "              gap,\"trajectory length=\",traj_len,\"final_point=\",\n",
    "              (n_samples-1)*gap+n_in+traj_len,\"data length\",data_tot.shape[1])\n",
    "\n",
    "    if(normalization==True):\n",
    "        trj=tr[:,n_in+gap*j:n_in+gap*j+traj_len]\n",
    "        test_data_new=(trj-(np.tile(np.transpose([np.mean(trj,axis=1)]),\n",
    "                                    (1,traj_len))))/(np.tile(np.transpose([np.std(trj,axis=1)]),\n",
    "                                                             (1,traj_len)))\n",
    "        test_times=np.cumsum(np.insert(np.diff(sel_times[:,n_in+gap*j:n_in+gap*j+traj_len])\n",
    "                                       ,0,0, axis=1),axis=1)\n",
    "#train_data_new=(data_tot[start_row:30000,:traj_len]-(np.tile(np.transpose([np.mean(data_tot[start_row:30000,:traj_len],axis=1)]),(1,traj_len))))/(np.tile(np.transpose([np.std(data_tot[start_row:30000,:traj_len],axis=1)]),(1,traj_len)))\n",
    "        test_labels_large=tar\n",
    "#test_labels=labels[start_row:num_row+start_row]\n",
    "        #print(test_data_new.shape)\n",
    "        #print(\"trj=\",trj.shape)\n",
    "        #print(\"sart=\",n_in+gap*j,\"end=\",n_in+gap*j+traj_len)\n",
    "        for j in range(1,n_samples):\n",
    "            trj=tr[:,n_in+gap*j:n_in+gap*j+traj_len]\n",
    "            #print(\"sart=\",n_in+gap*j,\"end=\",n_in+gap*j+traj_len)\n",
    "            #print(trj.shape)\n",
    "            test_data_new=np.concatenate((test_data_new,(trj-(np.tile(np.transpose([np.mean(trj,axis=1)]),(1,traj_len))))/(np.tile(np.transpose([np.std(trj,axis=1)]),(1,traj_len)))),axis=0)\n",
    "    #test_data_new=np.concatenate((test_data_new,(data_tot2[:,n_in+gap*j:n_in+gap*j+traj_len]-np.mean(data_tot2[:,n_in+gap*j:n_in+gap*j+traj_len]))/np.std(data_tot2[:,n_in+gap*j:n_in+gap*j+traj_len])),axis=0)\n",
    "            test_labels_large=np.append(test_labels_large,tar)\n",
    "            test_times=np.concatenate((test_times,np.cumsum(np.insert(np.diff(sel_times[:,n_in+gap*j:n_in+gap*j+traj_len]),0,0, axis=1),axis=1)),axis=0)\n",
    "    #test_labels=np.append(test_labels,many_label2)  \n",
    "    else:\n",
    "        test_data_new=tr[:,n_in+gap*j:n_in+gap*j+traj_len]\n",
    "        test_times=np.cumsum(np.insert(np.diff(sel_times[:,n_in+gap*j:n_in+gap*j+traj_len]),\n",
    "                                       0,0, axis=1),axis=1)\n",
    "#train_data_new=(data_tot[start_row:30000,:traj_len]-(np.tile(np.transpose([np.mean(data_tot[start_row:30000,:traj_len],axis=1)]),(1,traj_len))))/(np.tile(np.transpose([np.std(data_tot[start_row:30000,:traj_len],axis=1)]),(1,traj_len)))\n",
    "        test_labels_large=tar\n",
    "#test_labels=labels[start_row:num_row+start_row]\n",
    "        for j in range(1,n_samples):\n",
    "            test_data_new=np.concatenate((test_data_new,tr[:,n_in+gap*j:n_in+gap*j+traj_len]),\n",
    "                                         axis=0)\n",
    "    #test_data_new=np.concatenate((test_data_new,(data_tot2[:,n_in+gap*j:n_in+gap*j+traj_len]-np.mean(data_tot2[:,n_in+gap*j:n_in+gap*j+traj_len]))/np.std(data_tot2[:,n_in+gap*j:n_in+gap*j+traj_len])),axis=0)\n",
    "            test_labels_large=np.append(test_labels_large,tar)\n",
    "            test_times=np.concatenate((test_times,np.cumsum(\n",
    "                np.insert(np.diff(sel_times[:,n_in+gap*j:n_in+gap*j+traj_len]),0,0, axis=1),\n",
    "                axis=1)),axis=0)\n",
    "    #test_labels=np.append(test_labels,many_label2) \n",
    "        \n",
    "\n",
    "\n",
    "#normalization of time stamps, potentially dangerous!!!!!!!\n",
    "    test_times=test_times*p_p/traj_len\n",
    "    \n",
    "#RESHAPING\n",
    "    test_set=np.transpose(np.array((np.transpose(test_data_new),np.transpose(test_times))))  \n",
    "    return test_set, test_labels_large, test_data_new,test_times\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_9 (LSTM)                (None, None, 64)          16896     \n",
      "_________________________________________________________________\n",
      "lstm_10 (LSTM)               (None, 16)                5184      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 5)                 85        \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 5)                 30        \n",
      "=================================================================\n",
      "Total params: 22,195\n",
      "Trainable params: 22,195\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#LTSM network for learning  the Hurst exponet H, Normalized trajectories!!!\n",
    "\n",
    "#Building the network\n",
    "model_classi_norm_chi = Sequential()\n",
    "#first layer: LSTM of dimension 64\n",
    "model_classi_norm_chi.add(LSTM(64,\n",
    "                return_sequences=True,\n",
    "                dropout=0,\n",
    "                recurrent_dropout=0,\n",
    "                input_shape=(None, 1)\n",
    "                ))\n",
    "\n",
    "#second layer: LSTM of dimension 16\n",
    "model_classi_norm_chi.add(LSTM(16,\n",
    "                dropout=0,\n",
    "                recurrent_dropout=0))\n",
    "#Last layer, fully connected\n",
    "model_classi_norm_chi.add(Dense(5))\n",
    "model_classi_norm_chi.add(Dense(5,activation= 'softmax'))\n",
    "\n",
    "model_classi_norm_chi.compile(optimizer='adam',\n",
    "                loss='binary_crossentropy', \n",
    "                metrics=['accuracy'])\n",
    "\n",
    "#Printing a summary of the built network\n",
    "model_classi_norm_chi.summary()\n",
    "\n",
    "#Training the network first with minibatches of size 32 for 10 epochs, \n",
    "#then with minibatches of size 128\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traj length= 25 batch size= 32 \n",
      "\n",
      "n initial= 0 gap= 0\n",
      "warning!! Overlapping trajectories. gap= 0 trajectory length= 25 final_point= 25 data length 25\n",
      "traj length= 25 batch size= 32 \n",
      "\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/10\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 0.4767 - accuracy: 0.8001 - val_loss: 0.4596 - val_accuracy: 0.8049\n",
      "Epoch 2/10\n",
      "8000/8000 [==============================] - 7s 863us/step - loss: 0.4494 - accuracy: 0.8050 - val_loss: 0.4468 - val_accuracy: 0.8062\n",
      "Epoch 3/10\n",
      "8000/8000 [==============================] - 8s 950us/step - loss: 0.4346 - accuracy: 0.8121 - val_loss: 0.4294 - val_accuracy: 0.8150\n",
      "Epoch 4/10\n",
      "8000/8000 [==============================] - 8s 1ms/step - loss: 0.4231 - accuracy: 0.8160 - val_loss: 0.4165 - val_accuracy: 0.8189\n",
      "Epoch 5/10\n",
      "8000/8000 [==============================] - 11s 1ms/step - loss: 0.4093 - accuracy: 0.8212 - val_loss: 0.4073 - val_accuracy: 0.8209\n",
      "Epoch 6/10\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.4007 - accuracy: 0.8233 - val_loss: 0.4135 - val_accuracy: 0.8184\n",
      "Epoch 7/10\n",
      "8000/8000 [==============================] - 9s 1ms/step - loss: 0.3918 - accuracy: 0.8257 - val_loss: 0.3949 - val_accuracy: 0.8242\n",
      "Epoch 8/10\n",
      "8000/8000 [==============================] - 8s 1ms/step - loss: 0.3870 - accuracy: 0.8281 - val_loss: 0.3886 - val_accuracy: 0.8275\n",
      "Epoch 9/10\n",
      "8000/8000 [==============================] - 9s 1ms/step - loss: 0.3785 - accuracy: 0.8310 - val_loss: 0.3805 - val_accuracy: 0.8314\n",
      "Epoch 10/10\n",
      "8000/8000 [==============================] - 11s 1ms/step - loss: 0.3739 - accuracy: 0.8318 - val_loss: 0.3808 - val_accuracy: 0.8271\n",
      "traj length= 925 batch size= 32 \n",
      "\n",
      "n initial= 0 gap= 0\n",
      "warning!! Overlapping trajectories. gap= 0 trajectory length= 925 final_point= 925 data length 925\n",
      "traj length= 925 batch size= 32 \n",
      "\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/6\n",
      "8000/8000 [==============================] - 309s 39ms/step - loss: 0.4377 - accuracy: 0.8088 - val_loss: 0.4122 - val_accuracy: 0.8147\n",
      "Epoch 2/6\n",
      "8000/8000 [==============================] - 309s 39ms/step - loss: 0.4169 - accuracy: 0.8138 - val_loss: 0.4194 - val_accuracy: 0.8106\n",
      "Epoch 3/6\n",
      "8000/8000 [==============================] - 330s 41ms/step - loss: 0.4237 - accuracy: 0.8070 - val_loss: 0.4307 - val_accuracy: 0.8150\n",
      "Epoch 4/6\n",
      "8000/8000 [==============================] - 272s 34ms/step - loss: 0.4274 - accuracy: 0.8086 - val_loss: 0.4126 - val_accuracy: 0.8117\n",
      "Epoch 5/6\n",
      "8000/8000 [==============================] - 268s 33ms/step - loss: 0.4117 - accuracy: 0.8138 - val_loss: 0.3996 - val_accuracy: 0.8166\n",
      "Epoch 6/6\n",
      "8000/8000 [==============================] - 265s 33ms/step - loss: 0.4312 - accuracy: 0.8115 - val_loss: 0.5328 - val_accuracy: 0.7850\n",
      "traj length= 125 batch size= 32 \n",
      "\n",
      "n initial= 0 gap= 0\n",
      "warning!! Overlapping trajectories. gap= 0 trajectory length= 125 final_point= 125 data length 125\n",
      "traj length= 125 batch size= 32 \n",
      "\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/10\n",
      "8000/8000 [==============================] - 37s 5ms/step - loss: 0.4774 - accuracy: 0.8031 - val_loss: 0.4412 - val_accuracy: 0.8104\n",
      "Epoch 2/10\n",
      "8000/8000 [==============================] - 36s 4ms/step - loss: 0.4305 - accuracy: 0.8103 - val_loss: 0.4154 - val_accuracy: 0.8114\n",
      "Epoch 3/10\n",
      "8000/8000 [==============================] - 35s 4ms/step - loss: 0.4187 - accuracy: 0.8155 - val_loss: 0.4041 - val_accuracy: 0.8233\n",
      "Epoch 4/10\n",
      "8000/8000 [==============================] - 37s 5ms/step - loss: 0.3958 - accuracy: 0.8233 - val_loss: 0.3931 - val_accuracy: 0.8220\n",
      "Epoch 5/10\n",
      "8000/8000 [==============================] - 36s 5ms/step - loss: 0.3773 - accuracy: 0.8315 - val_loss: 0.3616 - val_accuracy: 0.8382\n",
      "Epoch 6/10\n",
      "8000/8000 [==============================] - 40s 5ms/step - loss: 0.3555 - accuracy: 0.8386 - val_loss: 0.3460 - val_accuracy: 0.8432\n",
      "Epoch 7/10\n",
      "8000/8000 [==============================] - 43s 5ms/step - loss: 0.3937 - accuracy: 0.8268 - val_loss: 0.3807 - val_accuracy: 0.8328\n",
      "Epoch 8/10\n",
      "8000/8000 [==============================] - 38s 5ms/step - loss: 0.3566 - accuracy: 0.8416 - val_loss: 0.3456 - val_accuracy: 0.8486\n",
      "Epoch 9/10\n",
      "8000/8000 [==============================] - 35s 4ms/step - loss: 0.3379 - accuracy: 0.8488 - val_loss: 0.3325 - val_accuracy: 0.8535\n",
      "Epoch 10/10\n",
      "8000/8000 [==============================] - 34s 4ms/step - loss: 0.3241 - accuracy: 0.8541 - val_loss: 0.3419 - val_accuracy: 0.8493\n",
      "traj length= 825 batch size= 32 \n",
      "\n",
      "n initial= 0 gap= 0\n",
      "warning!! Overlapping trajectories. gap= 0 trajectory length= 825 final_point= 825 data length 825\n",
      "traj length= 825 batch size= 32 \n",
      "\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/6\n",
      "8000/8000 [==============================] - 228s 28ms/step - loss: 0.3874 - accuracy: 0.8332 - val_loss: 0.3400 - val_accuracy: 0.8513\n",
      "Epoch 2/6\n",
      "8000/8000 [==============================] - 225s 28ms/step - loss: 0.3617 - accuracy: 0.8416 - val_loss: 0.3633 - val_accuracy: 0.8406\n",
      "Epoch 3/6\n",
      "8000/8000 [==============================] - 232s 29ms/step - loss: 0.3442 - accuracy: 0.8499 - val_loss: 0.3234 - val_accuracy: 0.8586\n",
      "Epoch 4/6\n",
      "8000/8000 [==============================] - 232s 29ms/step - loss: 0.3304 - accuracy: 0.8544 - val_loss: 0.3616 - val_accuracy: 0.8462\n",
      "Epoch 5/6\n",
      "8000/8000 [==============================] - 229s 29ms/step - loss: 0.3201 - accuracy: 0.8589 - val_loss: 0.3075 - val_accuracy: 0.8645\n",
      "Epoch 6/6\n",
      "8000/8000 [==============================] - 229s 29ms/step - loss: 0.3698 - accuracy: 0.8431 - val_loss: 0.3572 - val_accuracy: 0.8452\n",
      "traj length= 225 batch size= 32 \n",
      "\n",
      "n initial= 0 gap= 0\n",
      "warning!! Overlapping trajectories. gap= 0 trajectory length= 225 final_point= 225 data length 225\n",
      "traj length= 225 batch size= 32 \n",
      "\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/9\n",
      "8000/8000 [==============================] - 63s 8ms/step - loss: 0.3472 - accuracy: 0.8460 - val_loss: 0.3291 - val_accuracy: 0.8540\n",
      "Epoch 2/9\n",
      "8000/8000 [==============================] - 61s 8ms/step - loss: 0.3216 - accuracy: 0.8568 - val_loss: 0.3099 - val_accuracy: 0.8608\n",
      "Epoch 3/9\n",
      "8000/8000 [==============================] - 61s 8ms/step - loss: 0.3354 - accuracy: 0.8482 - val_loss: 0.3946 - val_accuracy: 0.8184\n",
      "Epoch 4/9\n",
      "8000/8000 [==============================] - 61s 8ms/step - loss: 0.3170 - accuracy: 0.8573 - val_loss: 0.3172 - val_accuracy: 0.8587\n",
      "Epoch 5/9\n",
      "8000/8000 [==============================] - 64s 8ms/step - loss: 0.3017 - accuracy: 0.8642 - val_loss: 0.2955 - val_accuracy: 0.8687\n",
      "Epoch 6/9\n",
      "8000/8000 [==============================] - 63s 8ms/step - loss: 0.3752 - accuracy: 0.8396 - val_loss: 0.3475 - val_accuracy: 0.8508\n",
      "Epoch 7/9\n",
      "8000/8000 [==============================] - 62s 8ms/step - loss: 0.3048 - accuracy: 0.8642 - val_loss: 0.2983 - val_accuracy: 0.8672\n",
      "Epoch 8/9\n",
      "8000/8000 [==============================] - 61s 8ms/step - loss: 0.2885 - accuracy: 0.8700 - val_loss: 0.2921 - val_accuracy: 0.8734\n",
      "Epoch 9/9\n",
      "8000/8000 [==============================] - 61s 8ms/step - loss: 0.2922 - accuracy: 0.8693 - val_loss: 0.2842 - val_accuracy: 0.8733\n",
      "traj length= 725 batch size= 32 \n",
      "\n",
      "n initial= 0 gap= 0\n",
      "warning!! Overlapping trajectories. gap= 0 trajectory length= 725 final_point= 725 data length 725\n",
      "traj length= 725 batch size= 32 \n",
      "\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/7\n",
      "8000/8000 [==============================] - 202s 25ms/step - loss: 0.2823 - accuracy: 0.8749 - val_loss: 0.3287 - val_accuracy: 0.8678\n",
      "Epoch 2/7\n",
      "8000/8000 [==============================] - 201s 25ms/step - loss: 0.3786 - accuracy: 0.8471 - val_loss: 0.4477 - val_accuracy: 0.8163\n",
      "Epoch 3/7\n",
      "8000/8000 [==============================] - 192s 24ms/step - loss: 0.4187 - accuracy: 0.8200 - val_loss: 0.4007 - val_accuracy: 0.8226\n",
      "Epoch 4/7\n",
      "8000/8000 [==============================] - 198s 25ms/step - loss: 0.3993 - accuracy: 0.8250 - val_loss: 0.3893 - val_accuracy: 0.8322\n",
      "Epoch 5/7\n",
      "8000/8000 [==============================] - 203s 25ms/step - loss: 0.3802 - accuracy: 0.8344 - val_loss: 0.3723 - val_accuracy: 0.8404\n",
      "Epoch 6/7\n",
      "8000/8000 [==============================] - 196s 24ms/step - loss: 0.3697 - accuracy: 0.8365 - val_loss: 0.3647 - val_accuracy: 0.8390\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/7\n",
      "8000/8000 [==============================] - 214s 27ms/step - loss: 0.3558 - accuracy: 0.8437 - val_loss: 0.3534 - val_accuracy: 0.8440\n",
      "traj length= 325 batch size= 32 \n",
      "\n",
      "n initial= 0 gap= 0\n",
      "warning!! Overlapping trajectories. gap= 0 trajectory length= 325 final_point= 325 data length 325\n",
      "traj length= 325 batch size= 32 \n",
      "\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/9\n",
      "8000/8000 [==============================] - 92s 12ms/step - loss: 0.3837 - accuracy: 0.8306 - val_loss: 0.3636 - val_accuracy: 0.8390\n",
      "Epoch 2/9\n",
      "8000/8000 [==============================] - 93s 12ms/step - loss: 0.3507 - accuracy: 0.8430 - val_loss: 0.3680 - val_accuracy: 0.8372\n",
      "Epoch 3/9\n",
      "8000/8000 [==============================] - 89s 11ms/step - loss: 0.3595 - accuracy: 0.8410 - val_loss: 0.3476 - val_accuracy: 0.8434\n",
      "Epoch 4/9\n",
      "8000/8000 [==============================] - 88s 11ms/step - loss: 0.3401 - accuracy: 0.8489 - val_loss: 0.3348 - val_accuracy: 0.8515\n",
      "Epoch 5/9\n",
      "8000/8000 [==============================] - 89s 11ms/step - loss: 0.3329 - accuracy: 0.8515 - val_loss: 0.3202 - val_accuracy: 0.8560\n",
      "Epoch 6/9\n",
      "8000/8000 [==============================] - 93s 12ms/step - loss: 0.3285 - accuracy: 0.8536 - val_loss: 0.3222 - val_accuracy: 0.8570\n",
      "Epoch 7/9\n",
      "8000/8000 [==============================] - 88s 11ms/step - loss: 0.3150 - accuracy: 0.8593 - val_loss: 0.3132 - val_accuracy: 0.8588\n",
      "Epoch 8/9\n",
      "8000/8000 [==============================] - 89s 11ms/step - loss: 0.3121 - accuracy: 0.8609 - val_loss: 0.3197 - val_accuracy: 0.8538\n",
      "Epoch 9/9\n",
      "8000/8000 [==============================] - 94s 12ms/step - loss: 0.3051 - accuracy: 0.8634 - val_loss: 0.3081 - val_accuracy: 0.8601\n",
      "traj length= 625 batch size= 32 \n",
      "\n",
      "n initial= 0 gap= 0\n",
      "warning!! Overlapping trajectories. gap= 0 trajectory length= 625 final_point= 625 data length 625\n",
      "traj length= 625 batch size= 32 \n",
      "\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/7\n",
      "8000/8000 [==============================] - 179s 22ms/step - loss: 0.3054 - accuracy: 0.8631 - val_loss: 0.2889 - val_accuracy: 0.8692\n",
      "Epoch 2/7\n",
      "8000/8000 [==============================] - 188s 23ms/step - loss: 0.3009 - accuracy: 0.8652 - val_loss: 0.3043 - val_accuracy: 0.8648\n",
      "Epoch 3/7\n",
      "8000/8000 [==============================] - 183s 23ms/step - loss: 0.2982 - accuracy: 0.8665 - val_loss: 0.3230 - val_accuracy: 0.8582\n",
      "Epoch 4/7\n",
      "8000/8000 [==============================] - 181s 23ms/step - loss: 0.2921 - accuracy: 0.8681 - val_loss: 0.3127 - val_accuracy: 0.8595\n",
      "Epoch 5/7\n",
      "8000/8000 [==============================] - 186s 23ms/step - loss: 0.2967 - accuracy: 0.8661 - val_loss: 0.3008 - val_accuracy: 0.8630\n",
      "Epoch 6/7\n",
      "8000/8000 [==============================] - 179s 22ms/step - loss: 0.2908 - accuracy: 0.8686 - val_loss: 0.2810 - val_accuracy: 0.8736\n",
      "Epoch 7/7\n",
      "8000/8000 [==============================] - 185s 23ms/step - loss: 0.2847 - accuracy: 0.8714 - val_loss: 0.2750 - val_accuracy: 0.8752\n",
      "traj length= 525 batch size= 32 \n",
      "\n",
      "n initial= 0 gap= 0\n",
      "warning!! Overlapping trajectories. gap= 0 trajectory length= 525 final_point= 525 data length 525\n",
      "traj length= 525 batch size= 32 \n",
      "\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/8\n",
      "8000/8000 [==============================] - 147s 18ms/step - loss: 0.2844 - accuracy: 0.8713 - val_loss: 0.2737 - val_accuracy: 0.8776\n",
      "Epoch 2/8\n",
      "8000/8000 [==============================] - 155s 19ms/step - loss: 0.2838 - accuracy: 0.8722 - val_loss: 0.2748 - val_accuracy: 0.8758\n",
      "Epoch 3/8\n",
      "8000/8000 [==============================] - 148s 18ms/step - loss: 0.2785 - accuracy: 0.8742 - val_loss: 0.2907 - val_accuracy: 0.8687\n",
      "Epoch 4/8\n",
      "8000/8000 [==============================] - 152s 19ms/step - loss: 0.2773 - accuracy: 0.8741 - val_loss: 0.2768 - val_accuracy: 0.8746\n",
      "Epoch 5/8\n",
      "8000/8000 [==============================] - 148s 18ms/step - loss: 0.2750 - accuracy: 0.8762 - val_loss: 0.2721 - val_accuracy: 0.8774\n",
      "Epoch 6/8\n",
      "8000/8000 [==============================] - 155s 19ms/step - loss: 0.2727 - accuracy: 0.8762 - val_loss: 0.2758 - val_accuracy: 0.8734\n",
      "Epoch 7/8\n",
      "8000/8000 [==============================] - 145s 18ms/step - loss: 0.2693 - accuracy: 0.8772 - val_loss: 0.2715 - val_accuracy: 0.8761\n",
      "Epoch 8/8\n",
      "8000/8000 [==============================] - 157s 20ms/step - loss: 0.2687 - accuracy: 0.8785 - val_loss: 0.2653 - val_accuracy: 0.8799\n",
      "traj length= 425 batch size= 32 \n",
      "\n",
      "n initial= 0 gap= 0\n",
      "warning!! Overlapping trajectories. gap= 0 trajectory length= 425 final_point= 425 data length 425\n",
      "traj length= 425 batch size= 32 \n",
      "\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/8\n",
      "8000/8000 [==============================] - 116s 15ms/step - loss: 0.2707 - accuracy: 0.8780 - val_loss: 0.2684 - val_accuracy: 0.8768\n",
      "Epoch 2/8\n",
      "8000/8000 [==============================] - 124s 15ms/step - loss: 0.2646 - accuracy: 0.8815 - val_loss: 0.2615 - val_accuracy: 0.8801\n",
      "Epoch 3/8\n",
      "8000/8000 [==============================] - 118s 15ms/step - loss: 0.2615 - accuracy: 0.8824 - val_loss: 0.2622 - val_accuracy: 0.8829\n",
      "Epoch 4/8\n",
      "8000/8000 [==============================] - 147s 18ms/step - loss: 0.2584 - accuracy: 0.8834 - val_loss: 0.2551 - val_accuracy: 0.8850\n",
      "Epoch 5/8\n",
      "8000/8000 [==============================] - 119s 15ms/step - loss: 0.2518 - accuracy: 0.8867 - val_loss: 0.2577 - val_accuracy: 0.8834\n",
      "Epoch 6/8\n",
      "8000/8000 [==============================] - 116s 14ms/step - loss: 0.2525 - accuracy: 0.8859 - val_loss: 0.2499 - val_accuracy: 0.8879\n",
      "Epoch 7/8\n",
      "8000/8000 [==============================] - 122s 15ms/step - loss: 0.2455 - accuracy: 0.8892 - val_loss: 0.2460 - val_accuracy: 0.8872\n",
      "Epoch 8/8\n",
      "8000/8000 [==============================] - 117s 15ms/step - loss: 0.2890 - accuracy: 0.8715 - val_loss: 0.2606 - val_accuracy: 0.8822\n",
      "traj length= 25 batch size= 128 \n",
      "\n",
      "n initial= 0 gap= 0\n",
      "warning!! Overlapping trajectories. gap= 0 trajectory length= 25 final_point= 25 data length 25\n",
      "traj length= 25 batch size= 128 \n",
      "\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/10\n",
      "8000/8000 [==============================] - 4s 496us/step - loss: 0.4747 - accuracy: 0.8026 - val_loss: 0.4341 - val_accuracy: 0.8148\n",
      "Epoch 2/10\n",
      "8000/8000 [==============================] - 4s 489us/step - loss: 0.4139 - accuracy: 0.8215 - val_loss: 0.4156 - val_accuracy: 0.8195\n",
      "Epoch 3/10\n",
      "8000/8000 [==============================] - 4s 494us/step - loss: 0.4016 - accuracy: 0.8245 - val_loss: 0.4061 - val_accuracy: 0.8224\n",
      "Epoch 4/10\n",
      "8000/8000 [==============================] - 4s 494us/step - loss: 0.3949 - accuracy: 0.8256 - val_loss: 0.3999 - val_accuracy: 0.8228\n",
      "Epoch 5/10\n",
      "8000/8000 [==============================] - 4s 488us/step - loss: 0.3901 - accuracy: 0.8266 - val_loss: 0.3949 - val_accuracy: 0.8247\n",
      "Epoch 6/10\n",
      "8000/8000 [==============================] - 4s 491us/step - loss: 0.3861 - accuracy: 0.8276 - val_loss: 0.3914 - val_accuracy: 0.8255\n",
      "Epoch 7/10\n",
      "8000/8000 [==============================] - 4s 482us/step - loss: 0.3830 - accuracy: 0.8285 - val_loss: 0.3886 - val_accuracy: 0.8272\n",
      "Epoch 8/10\n",
      "8000/8000 [==============================] - 4s 475us/step - loss: 0.3804 - accuracy: 0.8285 - val_loss: 0.3857 - val_accuracy: 0.8271\n",
      "Epoch 9/10\n",
      "8000/8000 [==============================] - 4s 492us/step - loss: 0.3774 - accuracy: 0.8296 - val_loss: 0.3836 - val_accuracy: 0.8281\n",
      "Epoch 10/10\n",
      "8000/8000 [==============================] - 4s 494us/step - loss: 0.3751 - accuracy: 0.8299 - val_loss: 0.3809 - val_accuracy: 0.8300\n",
      "traj length= 925 batch size= 128 \n",
      "\n",
      "n initial= 0 gap= 0\n",
      "warning!! Overlapping trajectories. gap= 0 trajectory length= 925 final_point= 925 data length 925\n",
      "traj length= 925 batch size= 128 \n",
      "\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/6\n",
      "8000/8000 [==============================] - 167s 21ms/step - loss: 0.4033 - accuracy: 0.8362 - val_loss: 0.2970 - val_accuracy: 0.8643\n",
      "Epoch 2/6\n",
      "8000/8000 [==============================] - 161s 20ms/step - loss: 0.2789 - accuracy: 0.8740 - val_loss: 0.2648 - val_accuracy: 0.8808\n",
      "Epoch 3/6\n",
      "8000/8000 [==============================] - 170s 21ms/step - loss: 0.2540 - accuracy: 0.8872 - val_loss: 0.2477 - val_accuracy: 0.8883\n",
      "Epoch 4/6\n",
      "8000/8000 [==============================] - 161s 20ms/step - loss: 0.2431 - accuracy: 0.8895 - val_loss: 0.2403 - val_accuracy: 0.8926\n",
      "Epoch 5/6\n",
      "8000/8000 [==============================] - 166s 21ms/step - loss: 0.2377 - accuracy: 0.8906 - val_loss: 0.2351 - val_accuracy: 0.8952\n",
      "Epoch 6/6\n",
      "8000/8000 [==============================] - 165s 21ms/step - loss: 0.2319 - accuracy: 0.8931 - val_loss: 0.2376 - val_accuracy: 0.8946\n",
      "traj length= 125 batch size= 128 \n",
      "\n",
      "n initial= 0 gap= 0\n",
      "warning!! Overlapping trajectories. gap= 0 trajectory length= 125 final_point= 125 data length 125\n",
      "traj length= 125 batch size= 128 \n",
      "\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/10\n",
      "8000/8000 [==============================] - 20s 3ms/step - loss: 0.3101 - accuracy: 0.8582 - val_loss: 0.2875 - val_accuracy: 0.8747\n",
      "Epoch 2/10\n",
      "8000/8000 [==============================] - 19s 2ms/step - loss: 0.2848 - accuracy: 0.8713 - val_loss: 0.2808 - val_accuracy: 0.8778\n",
      "Epoch 3/10\n",
      "8000/8000 [==============================] - 20s 2ms/step - loss: 0.2798 - accuracy: 0.8737 - val_loss: 0.2776 - val_accuracy: 0.8793\n",
      "Epoch 4/10\n",
      "8000/8000 [==============================] - 19s 2ms/step - loss: 0.2775 - accuracy: 0.8749 - val_loss: 0.2769 - val_accuracy: 0.8787\n",
      "Epoch 5/10\n",
      "8000/8000 [==============================] - 19s 2ms/step - loss: 0.2751 - accuracy: 0.8767 - val_loss: 0.2771 - val_accuracy: 0.8789\n",
      "Epoch 6/10\n",
      "8000/8000 [==============================] - 19s 2ms/step - loss: 0.2728 - accuracy: 0.8767 - val_loss: 0.2751 - val_accuracy: 0.8790\n",
      "Epoch 7/10\n",
      "8000/8000 [==============================] - 19s 2ms/step - loss: 0.2720 - accuracy: 0.8774 - val_loss: 0.2723 - val_accuracy: 0.8812\n",
      "Epoch 8/10\n",
      "8000/8000 [==============================] - 19s 2ms/step - loss: 0.2702 - accuracy: 0.8783 - val_loss: 0.2711 - val_accuracy: 0.8818\n",
      "Epoch 9/10\n",
      "8000/8000 [==============================] - 19s 2ms/step - loss: 0.2676 - accuracy: 0.8789 - val_loss: 0.2759 - val_accuracy: 0.8788\n",
      "Epoch 10/10\n",
      "8000/8000 [==============================] - 19s 2ms/step - loss: 0.2663 - accuracy: 0.8803 - val_loss: 0.2690 - val_accuracy: 0.8823\n",
      "traj length= 825 batch size= 128 \n",
      "\n",
      "n initial= 0 gap= 0\n",
      "warning!! Overlapping trajectories. gap= 0 trajectory length= 825 final_point= 825 data length 825\n",
      "traj length= 825 batch size= 128 \n",
      "\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/6\n",
      "8000/8000 [==============================] - 145s 18ms/step - loss: 0.3213 - accuracy: 0.8643 - val_loss: 0.2438 - val_accuracy: 0.8917\n",
      "Epoch 2/6\n",
      "8000/8000 [==============================] - 140s 18ms/step - loss: 0.2377 - accuracy: 0.8913 - val_loss: 0.2350 - val_accuracy: 0.8926\n",
      "Epoch 3/6\n",
      "8000/8000 [==============================] - 144s 18ms/step - loss: 0.2312 - accuracy: 0.8945 - val_loss: 0.2318 - val_accuracy: 0.8945\n",
      "Epoch 4/6\n",
      "8000/8000 [==============================] - 141s 18ms/step - loss: 0.2247 - accuracy: 0.8962 - val_loss: 0.2277 - val_accuracy: 0.8950\n",
      "Epoch 5/6\n",
      "8000/8000 [==============================] - 145s 18ms/step - loss: 0.2255 - accuracy: 0.8967 - val_loss: 0.2240 - val_accuracy: 0.8983\n",
      "Epoch 6/6\n",
      "8000/8000 [==============================] - 141s 18ms/step - loss: 0.2224 - accuracy: 0.8979 - val_loss: 0.2236 - val_accuracy: 0.8946\n",
      "traj length= 225 batch size= 128 \n",
      "\n",
      "n initial= 0 gap= 0\n",
      "warning!! Overlapping trajectories. gap= 0 trajectory length= 225 final_point= 225 data length 225\n",
      "traj length= 225 batch size= 128 \n",
      "\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/9\n",
      "8000/8000 [==============================] - 35s 4ms/step - loss: 0.2576 - accuracy: 0.8816 - val_loss: 0.2468 - val_accuracy: 0.8868\n",
      "Epoch 2/9\n",
      "8000/8000 [==============================] - 35s 4ms/step - loss: 0.2443 - accuracy: 0.8878 - val_loss: 0.2439 - val_accuracy: 0.8893\n",
      "Epoch 3/9\n",
      "8000/8000 [==============================] - 35s 4ms/step - loss: 0.2419 - accuracy: 0.8890 - val_loss: 0.2427 - val_accuracy: 0.8902\n",
      "Epoch 4/9\n",
      "8000/8000 [==============================] - 38s 5ms/step - loss: 0.2387 - accuracy: 0.8907 - val_loss: 0.2427 - val_accuracy: 0.8904\n",
      "Epoch 5/9\n",
      "8000/8000 [==============================] - 36s 4ms/step - loss: 0.2373 - accuracy: 0.8907 - val_loss: 0.2409 - val_accuracy: 0.8878\n",
      "Epoch 6/9\n",
      "8000/8000 [==============================] - 37s 5ms/step - loss: 0.2369 - accuracy: 0.8914 - val_loss: 0.2398 - val_accuracy: 0.8892\n",
      "Epoch 7/9\n",
      "8000/8000 [==============================] - 35s 4ms/step - loss: 0.2363 - accuracy: 0.8918 - val_loss: 0.2391 - val_accuracy: 0.8937\n",
      "Epoch 8/9\n",
      "8000/8000 [==============================] - 35s 4ms/step - loss: 0.2322 - accuracy: 0.8928 - val_loss: 0.2368 - val_accuracy: 0.8904\n",
      "Epoch 9/9\n",
      "8000/8000 [==============================] - 35s 4ms/step - loss: 0.2307 - accuracy: 0.8936 - val_loss: 0.2343 - val_accuracy: 0.8952\n",
      "traj length= 725 batch size= 128 \n",
      "\n",
      "n initial= 0 gap= 0\n",
      "warning!! Overlapping trajectories. gap= 0 trajectory length= 725 final_point= 725 data length 725\n",
      "traj length= 725 batch size= 128 \n",
      "\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/7\n",
      "8000/8000 [==============================] - 126s 16ms/step - loss: 0.2336 - accuracy: 0.8940 - val_loss: 0.2370 - val_accuracy: 0.8913\n",
      "Epoch 2/7\n",
      "8000/8000 [==============================] - 125s 16ms/step - loss: 0.2154 - accuracy: 0.9007 - val_loss: 0.2083 - val_accuracy: 0.9050\n",
      "Epoch 3/7\n",
      "8000/8000 [==============================] - 122s 15ms/step - loss: 0.2065 - accuracy: 0.9057 - val_loss: 0.2126 - val_accuracy: 0.9017\n",
      "Epoch 4/7\n",
      "8000/8000 [==============================] - 126s 16ms/step - loss: 0.2058 - accuracy: 0.9053 - val_loss: 0.2028 - val_accuracy: 0.9061\n",
      "Epoch 5/7\n",
      "8000/8000 [==============================] - 123s 15ms/step - loss: 0.1999 - accuracy: 0.9081 - val_loss: 0.2066 - val_accuracy: 0.9043\n",
      "Epoch 6/7\n",
      "8000/8000 [==============================] - 127s 16ms/step - loss: 0.1972 - accuracy: 0.9086 - val_loss: 0.1982 - val_accuracy: 0.9100\n",
      "Epoch 7/7\n",
      "8000/8000 [==============================] - 134s 17ms/step - loss: 0.1943 - accuracy: 0.9122 - val_loss: 0.1982 - val_accuracy: 0.9083\n",
      "traj length= 325 batch size= 128 \n",
      "\n",
      "n initial= 0 gap= 0\n",
      "warning!! Overlapping trajectories. gap= 0 trajectory length= 325 final_point= 325 data length 325\n",
      "traj length= 325 batch size= 128 \n",
      "\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/9\n",
      "8000/8000 [==============================] - 53s 7ms/step - loss: 0.2228 - accuracy: 0.8964 - val_loss: 0.2315 - val_accuracy: 0.8950\n",
      "Epoch 2/9\n",
      "8000/8000 [==============================] - 51s 6ms/step - loss: 0.2130 - accuracy: 0.9013 - val_loss: 0.2262 - val_accuracy: 0.8957\n",
      "Epoch 3/9\n",
      "8000/8000 [==============================] - 55s 7ms/step - loss: 0.2104 - accuracy: 0.9029 - val_loss: 0.2271 - val_accuracy: 0.8971\n",
      "Epoch 4/9\n",
      "8000/8000 [==============================] - 52s 6ms/step - loss: 0.2087 - accuracy: 0.9043 - val_loss: 0.2281 - val_accuracy: 0.8956\n",
      "Epoch 5/9\n",
      "8000/8000 [==============================] - 51s 6ms/step - loss: 0.2039 - accuracy: 0.9062 - val_loss: 0.2250 - val_accuracy: 0.8943\n",
      "Epoch 6/9\n",
      "8000/8000 [==============================] - 51s 6ms/step - loss: 0.2062 - accuracy: 0.9052 - val_loss: 0.2241 - val_accuracy: 0.8957\n",
      "Epoch 7/9\n",
      "8000/8000 [==============================] - 52s 6ms/step - loss: 0.2017 - accuracy: 0.9081 - val_loss: 0.2217 - val_accuracy: 0.8970\n",
      "Epoch 8/9\n",
      "8000/8000 [==============================] - 51s 6ms/step - loss: 0.2011 - accuracy: 0.9087 - val_loss: 0.2204 - val_accuracy: 0.8982\n",
      "Epoch 9/9\n",
      "8000/8000 [==============================] - 56s 7ms/step - loss: 0.1998 - accuracy: 0.9087 - val_loss: 0.2242 - val_accuracy: 0.8971\n",
      "traj length= 625 batch size= 128 \n",
      "\n",
      "n initial= 0 gap= 0\n",
      "warning!! Overlapping trajectories. gap= 0 trajectory length= 625 final_point= 625 data length 625\n",
      "traj length= 625 batch size= 128 \n",
      "\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/7\n",
      "8000/8000 [==============================] - 104s 13ms/step - loss: 0.1924 - accuracy: 0.9129 - val_loss: 0.1811 - val_accuracy: 0.9129\n",
      "Epoch 2/7\n",
      "8000/8000 [==============================] - 103s 13ms/step - loss: 0.1881 - accuracy: 0.9145 - val_loss: 0.1888 - val_accuracy: 0.9131\n",
      "Epoch 3/7\n",
      "8000/8000 [==============================] - 109s 14ms/step - loss: 0.1847 - accuracy: 0.9154 - val_loss: 0.1877 - val_accuracy: 0.9094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/7\n",
      "8000/8000 [==============================] - 108s 13ms/step - loss: 0.1837 - accuracy: 0.9151 - val_loss: 0.1788 - val_accuracy: 0.9144\n",
      "Epoch 5/7\n",
      "8000/8000 [==============================] - 107s 13ms/step - loss: 0.1840 - accuracy: 0.9157 - val_loss: 0.1801 - val_accuracy: 0.9123\n",
      "Epoch 6/7\n",
      "8000/8000 [==============================] - 113s 14ms/step - loss: 0.1801 - accuracy: 0.9178 - val_loss: 0.1814 - val_accuracy: 0.9102\n",
      "Epoch 7/7\n",
      "8000/8000 [==============================] - 106s 13ms/step - loss: 0.1788 - accuracy: 0.9197 - val_loss: 0.1789 - val_accuracy: 0.9140\n",
      "traj length= 525 batch size= 128 \n",
      "\n",
      "n initial= 0 gap= 0\n",
      "warning!! Overlapping trajectories. gap= 0 trajectory length= 525 final_point= 525 data length 525\n",
      "traj length= 525 batch size= 128 \n",
      "\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/8\n",
      "8000/8000 [==============================] - 87s 11ms/step - loss: 0.1901 - accuracy: 0.9121 - val_loss: 0.1954 - val_accuracy: 0.9079\n",
      "Epoch 2/8\n",
      "8000/8000 [==============================] - 89s 11ms/step - loss: 0.1862 - accuracy: 0.9140 - val_loss: 0.1863 - val_accuracy: 0.9125\n",
      "Epoch 3/8\n",
      "8000/8000 [==============================] - 87s 11ms/step - loss: 0.1803 - accuracy: 0.9172 - val_loss: 0.1833 - val_accuracy: 0.9130\n",
      "Epoch 4/8\n",
      "8000/8000 [==============================] - 86s 11ms/step - loss: 0.1803 - accuracy: 0.9164 - val_loss: 0.1840 - val_accuracy: 0.9113\n",
      "Epoch 5/8\n",
      "8000/8000 [==============================] - 89s 11ms/step - loss: 0.1792 - accuracy: 0.9168 - val_loss: 0.1843 - val_accuracy: 0.9170\n",
      "Epoch 6/8\n",
      "8000/8000 [==============================] - 88s 11ms/step - loss: 0.1784 - accuracy: 0.9194 - val_loss: 0.1892 - val_accuracy: 0.9133\n",
      "Epoch 7/8\n",
      "8000/8000 [==============================] - 86s 11ms/step - loss: 0.1786 - accuracy: 0.9172 - val_loss: 0.1829 - val_accuracy: 0.9146\n",
      "Epoch 8/8\n",
      "8000/8000 [==============================] - 86s 11ms/step - loss: 0.1771 - accuracy: 0.9192 - val_loss: 0.1919 - val_accuracy: 0.9100\n",
      "traj length= 425 batch size= 128 \n",
      "\n",
      "n initial= 0 gap= 0\n",
      "warning!! Overlapping trajectories. gap= 0 trajectory length= 425 final_point= 425 data length 425\n",
      "traj length= 425 batch size= 128 \n",
      "\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/8\n",
      "8000/8000 [==============================] - 73s 9ms/step - loss: 0.1938 - accuracy: 0.9104 - val_loss: 0.1946 - val_accuracy: 0.9107\n",
      "Epoch 2/8\n",
      "8000/8000 [==============================] - 69s 9ms/step - loss: 0.1858 - accuracy: 0.9125 - val_loss: 0.1926 - val_accuracy: 0.9145\n",
      "Epoch 3/8\n",
      "8000/8000 [==============================] - 69s 9ms/step - loss: 0.1850 - accuracy: 0.9130 - val_loss: 0.1915 - val_accuracy: 0.9128\n",
      "Epoch 4/8\n",
      "8000/8000 [==============================] - 69s 9ms/step - loss: 0.1792 - accuracy: 0.9177 - val_loss: 0.1960 - val_accuracy: 0.9121\n",
      "Epoch 5/8\n",
      "8000/8000 [==============================] - 73s 9ms/step - loss: 0.1794 - accuracy: 0.9189 - val_loss: 0.1997 - val_accuracy: 0.9079\n",
      "Epoch 6/8\n",
      "8000/8000 [==============================] - 69s 9ms/step - loss: 0.1811 - accuracy: 0.9162 - val_loss: 0.1920 - val_accuracy: 0.9104\n",
      "Epoch 7/8\n",
      "8000/8000 [==============================] - 69s 9ms/step - loss: 0.1773 - accuracy: 0.9195 - val_loss: 0.1964 - val_accuracy: 0.9100\n",
      "Epoch 8/8\n",
      "8000/8000 [==============================] - 69s 9ms/step - loss: 0.1752 - accuracy: 0.9206 - val_loss: 0.1993 - val_accuracy: 0.9085\n"
     ]
    }
   ],
   "source": [
    "for batch_size in [32,128]:#[32, 128]:\n",
    "    j=0\n",
    "   \n",
    "    for i in [25,925,125,825,225,725,325,625,525,425]:\n",
    "    \n",
    "        print('traj length=',i,'batch size=', batch_size,'\\n')\n",
    "\n",
    "        test_tim_step=np.arange(i)\n",
    "        show_time_coll=np.tile(test_tim_step,(len(bb[i]),1))\n",
    "        data_show,label_show,traj_show,times_show=data_split(np.asarray(bb[i]),\n",
    "                                                             show_time_coll,labels=np.asarray(ccm[i]),\n",
    "                                                             start_row=0,num_row=10000,traj_len=i,n_in=0,\n",
    "                                                             n_samples=1,p_p=1,hmin=0.25,hmax=0.75,\n",
    "                                                             limith=False,normalization=True)\n",
    "\n",
    "        print('traj length=',i,'batch size=', batch_size,'\\n')\n",
    "        history_classi_norm_chi = model_classi_norm_chi.fit(traj_show.reshape(len(traj_show),i,1), \n",
    "                        label_show,validation_split=0.2,\n",
    "                        epochs=10-int(i/200), \n",
    "                        batch_size=batch_size,\n",
    "                        shuffle=True)\n",
    "    #                     ,validation_data=(data_val, \n",
    "    #                     label_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.0000001 , 1.0000001 , 0.99999994, 1.        , 1.        ,\n",
       "       0.99999994, 1.        , 1.        , 1.        , 1.0000001 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(model_classi_norm_chi.predict(traj_show.reshape(len(traj_show),i,1)[:10]),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.99999994, 0.9999999 , 1.0000001 , 0.9999999 ,\n",
       "       1.0000001 , 0.9999999 , 1.        , 1.        , 1.        ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(model_classi_norm_chi.predict(traj_show.reshape(len(traj_show),i,1)[:10]),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n initial= 0 gap= 0\n",
      "warning!! Overlapping trajectories. gap= 0 trajectory length= 25 final_point= 25 data length 25\n",
      "0.34\n",
      "n initial= 0 gap= 0\n",
      "warning!! Overlapping trajectories. gap= 0 trajectory length= 125 final_point= 125 data length 125\n",
      "0.589\n",
      "n initial= 0 gap= 0\n",
      "warning!! Overlapping trajectories. gap= 0 trajectory length= 225 final_point= 225 data length 225\n",
      "0.684\n",
      "n initial= 0 gap= 0\n",
      "warning!! Overlapping trajectories. gap= 0 trajectory length= 325 final_point= 325 data length 325\n",
      "0.747\n",
      "n initial= 0 gap= 0\n",
      "warning!! Overlapping trajectories. gap= 0 trajectory length= 425 final_point= 425 data length 425\n",
      "0.768\n",
      "n initial= 0 gap= 0\n",
      "warning!! Overlapping trajectories. gap= 0 trajectory length= 525 final_point= 525 data length 525\n",
      "0.793\n",
      "n initial= 0 gap= 0\n",
      "warning!! Overlapping trajectories. gap= 0 trajectory length= 625 final_point= 625 data length 625\n",
      "0.791\n",
      "n initial= 0 gap= 0\n",
      "warning!! Overlapping trajectories. gap= 0 trajectory length= 725 final_point= 725 data length 725\n",
      "0.802\n",
      "n initial= 0 gap= 0\n",
      "warning!! Overlapping trajectories. gap= 0 trajectory length= 825 final_point= 825 data length 825\n",
      "0.78\n",
      "n initial= 0 gap= 0\n",
      "warning!! Overlapping trajectories. gap= 0 trajectory length= 925 final_point= 925 data length 925\n",
      "0.764\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "for i in cl:\n",
    "    groundtruth = np.argmax(ccvm[i], axis = 1)\n",
    "    test_tim_step=np.arange(i)\n",
    "    show_time_coll=np.tile(test_tim_step,(len(bbv[i]),1))\n",
    "    data_show,label_show,traj_show,times_show=data_split(np.asarray(bbv[i]),\n",
    "                                                             show_time_coll,labels=np.asarray(ccvm[i]),\n",
    "                                                             start_row=0,num_row=10000,traj_len=i,n_in=0,\n",
    "                                                             n_samples=1,p_p=1,hmin=0.25,hmax=0.75,\n",
    "                                                             limith=False,normalization=True)\n",
    "\n",
    "    predictions = np.argmax(model_classi_norm_chi.predict(traj_show.reshape(len(traj_show),i,1)), axis = 1)\n",
    "\n",
    "    print(f1_score(groundtruth, predictions, average='micro'))\n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "conf = confusion_matrix(groundtruth, predictions)\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (7,7))\n",
    "ax.matshow(conf)\n",
    "for (i, j), z in np.ndenumerate(conf):\n",
    "    ax.text(j, i, '{:0.3f}'.format(z), ha='center', va='center', fontsize = 16)\n",
    "ax.set_xticklabels(['c','ATTM','CTRW','FBM','LW','SBM'], fontsize = 16)\n",
    "ax.set_yticklabels(['a','ATTM','CTRW','FBM','LW','SBM'], fontsize = 16)\n",
    "ax.set_xlabel('Predicted class', fontsize = 16)\n",
    "ax.set_ylabel('Groundtruth', fontsize = 16)\n",
    "ax.xaxis.set_ticks_position('bottom') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "trajs_from_files = csv.reader(open('datasets/development_for_scoring_new/task2.txt','r'), delimiter=';', \n",
    "                                        lineterminator='\\n',quoting=csv.QUOTE_NONNUMERIC)\n",
    "validation = [[],[],[]]\n",
    "for trajs in enumerate(trajs_from_files):\n",
    "    validation[int(trajs[1][0])-1].append(trajs[1][1:])\n",
    "\n",
    "predictions=[]\n",
    "\n",
    "for traj in validation[0]:\n",
    "    traj=(traj-np.mean(traj))/np.std(traj)\n",
    "    #print(np.mean(traj),np.std(traj))\n",
    "    predictions.append(model_classi_norm_chi.predict(np.asarray(traj).reshape(1,len(traj),1)).flatten())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0006655277"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_to_txt = np.ones((len(predictions), 6))\n",
    "for i in range(len(predictions)):\n",
    "    for j in range(5):\n",
    "        \n",
    "        pred_to_txt[i, j+1] = predictions[i][j]\n",
    "\n",
    "np.savetxt('task2.txt', pred_to_txt.astype(float), fmt = '%1.5f', delimiter = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_classi_norm_chi.save('task2_1d_classi_norm_chi.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specialize the net on traj that are 100 long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_classi_norm_100=load_model('task2_1d_classi_norm_chi.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a dataset for task(s) 2 and dimension(s) 1.\n",
      "Generating dataset for dimension 1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stebo/anaconda3/lib/python3.7/site-packages/fbm/fbm.py:172: UserWarning: Combination of increments n and Hurst value H invalid for Davies-Harte method. Reverting to Hosking method. Occurs when n is small and Hurst is close to 1. \n",
      "  \"Combination of increments n and Hurst value H \"\n",
      "/Users/stebo/anaconda3/lib/python3.7/site-packages/andi/diffusion_models.py:85: RuntimeWarning: overflow encountered in power\n",
      "  dt = (1-np.random.rand(T))**(-1/sigma)\n"
     ]
    }
   ],
   "source": [
    "bb={}\n",
    "cc={}\n",
    "cl=[100]\n",
    "j=0\n",
    "for i in cl:\n",
    "    X1, Y1, X2, Y2, X3, Y3 = AD.andi_dataset(N = 50000, tasks = 2, dimensions = 1,\n",
    "                                             min_T = i, max_T = i+1, save_dataset=True, path_datasets=str(i)+'multi')\n",
    "    bb[i]=X2[0]\n",
    "    cc[i]=Y2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "ccm={}\n",
    "for i in cl:\n",
    "    ccm[i]=np.zeros((len(cc[i]),5))\n",
    "    print(ccm[i])\n",
    "    print(ccm[i][j][2])\n",
    "    for j in range(len(cc[i])):\n",
    "        ccm[i][j][int(cc[i][j])]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{100: array([[0., 1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        ...,\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.]])}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ccm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traj length= 100 batch size= 32 \n",
      "\n",
      "n initial= 0 gap= 0\n",
      "warning!! Overlapping trajectories. gap= 0 trajectory length= 100 final_point= 100 data length 100\n",
      "traj length= 100 batch size= 32 \n",
      "\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "40000/40000 [==============================] - 149s 4ms/step - loss: 0.2630 - accuracy: 0.8793 - val_loss: 0.2549 - val_accuracy: 0.8825\n",
      "Epoch 2/10\n",
      "40000/40000 [==============================] - 141s 4ms/step - loss: 0.2499 - accuracy: 0.8853 - val_loss: 0.2508 - val_accuracy: 0.8860\n",
      "Epoch 3/10\n",
      "40000/40000 [==============================] - 165s 4ms/step - loss: 0.2430 - accuracy: 0.8882 - val_loss: 0.2448 - val_accuracy: 0.8874\n",
      "Epoch 4/10\n",
      "40000/40000 [==============================] - 145s 4ms/step - loss: 0.2381 - accuracy: 0.8904 - val_loss: 0.2562 - val_accuracy: 0.8814\n",
      "Epoch 5/10\n",
      "40000/40000 [==============================] - 135s 3ms/step - loss: 0.2338 - accuracy: 0.8919 - val_loss: 0.2377 - val_accuracy: 0.8897\n",
      "Epoch 6/10\n",
      "40000/40000 [==============================] - 130s 3ms/step - loss: 0.2306 - accuracy: 0.8932 - val_loss: 0.2373 - val_accuracy: 0.8900\n",
      "Epoch 7/10\n",
      "40000/40000 [==============================] - 131s 3ms/step - loss: 0.2279 - accuracy: 0.8941 - val_loss: 0.2317 - val_accuracy: 0.8926\n",
      "Epoch 8/10\n",
      "40000/40000 [==============================] - 131s 3ms/step - loss: 0.2251 - accuracy: 0.8964 - val_loss: 0.2374 - val_accuracy: 0.8889\n",
      "Epoch 9/10\n",
      "40000/40000 [==============================] - 136s 3ms/step - loss: 0.2230 - accuracy: 0.8970 - val_loss: 0.2299 - val_accuracy: 0.8932\n",
      "Epoch 10/10\n",
      "40000/40000 [==============================] - 184s 5ms/step - loss: 0.2207 - accuracy: 0.8983 - val_loss: 0.2314 - val_accuracy: 0.8926\n",
      "traj length= 100 batch size= 128 \n",
      "\n",
      "n initial= 0 gap= 0\n",
      "warning!! Overlapping trajectories. gap= 0 trajectory length= 100 final_point= 100 data length 100\n",
      "traj length= 100 batch size= 128 \n",
      "\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "40000/40000 [==============================] - 68s 2ms/step - loss: 0.2113 - accuracy: 0.9031 - val_loss: 0.2259 - val_accuracy: 0.8947\n",
      "Epoch 2/10\n",
      "40000/40000 [==============================] - 54s 1ms/step - loss: 0.2095 - accuracy: 0.9037 - val_loss: 0.2279 - val_accuracy: 0.8926\n",
      "Epoch 3/10\n",
      "40000/40000 [==============================] - 61s 2ms/step - loss: 0.2085 - accuracy: 0.9042 - val_loss: 0.2271 - val_accuracy: 0.8934\n",
      "Epoch 4/10\n",
      "40000/40000 [==============================] - 55s 1ms/step - loss: 0.2082 - accuracy: 0.9043 - val_loss: 0.2268 - val_accuracy: 0.8948\n",
      "Epoch 5/10\n",
      "40000/40000 [==============================] - 56s 1ms/step - loss: 0.2078 - accuracy: 0.9042 - val_loss: 0.2254 - val_accuracy: 0.8948\n",
      "Epoch 6/10\n",
      "40000/40000 [==============================] - 54s 1ms/step - loss: 0.2070 - accuracy: 0.9054 - val_loss: 0.2301 - val_accuracy: 0.8919\n",
      "Epoch 7/10\n",
      "40000/40000 [==============================] - 54s 1ms/step - loss: 0.2064 - accuracy: 0.9052 - val_loss: 0.2244 - val_accuracy: 0.8956\n",
      "Epoch 8/10\n",
      "40000/40000 [==============================] - 54s 1ms/step - loss: 0.2056 - accuracy: 0.9056 - val_loss: 0.2267 - val_accuracy: 0.8953\n",
      "Epoch 9/10\n",
      "40000/40000 [==============================] - 54s 1ms/step - loss: 0.2042 - accuracy: 0.9061 - val_loss: 0.2294 - val_accuracy: 0.8933\n",
      "Epoch 10/10\n",
      "40000/40000 [==============================] - 54s 1ms/step - loss: 0.2038 - accuracy: 0.9063 - val_loss: 0.2272 - val_accuracy: 0.8943\n"
     ]
    }
   ],
   "source": [
    "for batch_size in [32,128]:#[32, 128]:\n",
    "    j=0\n",
    "   \n",
    "    for i in [100]:\n",
    "    \n",
    "        print('traj length=',i,'batch size=', batch_size,'\\n')\n",
    "\n",
    "        test_tim_step=np.arange(i)\n",
    "        show_time_coll=np.tile(test_tim_step,(len(bb[i]),1))\n",
    "        data_show,label_show,traj_show,times_show=data_split(np.asarray(bb[i]),\n",
    "                                                             show_time_coll,labels=np.asarray(ccm[i]),\n",
    "                                                             start_row=0,num_row=len(bb[i]),traj_len=i,n_in=0,\n",
    "                                                             n_samples=1,p_p=1,hmin=0,hmax=2,\n",
    "                                                             limith=False,normalization=True)\n",
    "\n",
    "        print('traj length=',i,'batch size=', batch_size,'\\n')\n",
    "        history_classi_norm_100 = model_classi_norm_100.fit(traj_show.reshape(len(traj_show),i,1), \n",
    "                        label_show,validation_split=0.2,\n",
    "                        epochs=10-int(i/200), \n",
    "                        batch_size=batch_size,\n",
    "                        shuffle=True)\n",
    "    #                     ,validation_data=(data_val, \n",
    "    #                     label_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a dataset for task(s) 2 and dimension(s) 1.\n",
      "Generating dataset for dimension 1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stebo/anaconda3/lib/python3.7/site-packages/fbm/fbm.py:172: UserWarning: Combination of increments n and Hurst value H invalid for Davies-Harte method. Reverting to Hosking method. Occurs when n is small and Hurst is close to 1. \n",
      "  \"Combination of increments n and Hurst value H \"\n",
      "/Users/stebo/anaconda3/lib/python3.7/site-packages/andi/diffusion_models.py:85: RuntimeWarning: overflow encountered in power\n",
      "  dt = (1-np.random.rand(T))**(-1/sigma)\n"
     ]
    }
   ],
   "source": [
    "bbv={}\n",
    "ccv={}\n",
    "cl=[100]\n",
    "j=0\n",
    "for i in cl:\n",
    "    X1, Y1, X2, Y2, X3, Y3 = AD.andi_dataset(N = 1000, tasks = 2, dimensions = 1,\n",
    "                                             min_T = i, max_T = i+1, save_dataset=True, path_datasets=str(i)+'multi_val')\n",
    "    bbv[i]=X2[0]\n",
    "    ccv[i]=Y2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "ccvm={}\n",
    "for i in cl:\n",
    "    ccvm[i]=np.zeros((len(ccv[i]),5))\n",
    "    print(ccvm[i])\n",
    "    print(ccvm[i][j][2])\n",
    "    for j in range(len(ccv[i])):\n",
    "        ccvm[i][j][int(ccv[i][j])]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n initial= 0 gap= 0\n",
      "warning!! Overlapping trajectories. gap= 0 trajectory length= 100 final_point= 100 data length 100\n",
      "0.691\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "for i in np.array([100]):\n",
    "    groundtruth = np.argmax(ccvm[i], axis = 1)\n",
    "    test_tim_step=np.arange(i)\n",
    "    show_time_coll=np.tile(test_tim_step,(len(bbv[i]),1))\n",
    "    data_show,label_show,traj_show,times_show=data_split(np.asarray(bbv[i]),\n",
    "                                                             show_time_coll,labels=np.asarray(ccvm[i]),\n",
    "                                                             start_row=0,num_row=len(bbv[i]),traj_len=i,n_in=0,\n",
    "                                                             n_samples=1,p_p=1,hmin=0.25,hmax=0.75,\n",
    "                                                             limith=False,normalization=True)\n",
    "\n",
    "    predictions = np.argmax(model_classi_norm_100.predict(traj_show.reshape(len(traj_show),i,1)), axis = 1)\n",
    "\n",
    "    print(f1_score(groundtruth, predictions, average='micro'))\n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "conf = confusion_matrix(groundtruth, predictions)\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (7,7))\n",
    "ax.matshow(conf)\n",
    "for (i, j), z in np.ndenumerate(conf):\n",
    "    ax.text(j, i, '{:0.3f}'.format(z), ha='center', va='center', fontsize = 16)\n",
    "ax.set_xticklabels(['c','ATTM','CTRW','FBM','LW','SBM'], fontsize = 16)\n",
    "ax.set_yticklabels(['a','ATTM','CTRW','FBM','LW','SBM'], fontsize = 16)\n",
    "ax.set_xlabel('Predicted class', fontsize = 16)\n",
    "ax.set_ylabel('Groundtruth', fontsize = 16)\n",
    "ax.xaxis.set_ticks_position('bottom') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_classi_norm_100.save('task2_1d_classi_norm_100.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specialize the net on traj that are 750 long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_classi_norm_750=load_model('task2_1d_classi_norm_chi.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a dataset for task(s) 2 and dimension(s) 1.\n",
      "Generating dataset for dimension 1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stebo/anaconda3/lib/python3.7/site-packages/fbm/fbm.py:172: UserWarning: Combination of increments n and Hurst value H invalid for Davies-Harte method. Reverting to Hosking method. Occurs when n is small and Hurst is close to 1. \n",
      "  \"Combination of increments n and Hurst value H \"\n",
      "/Users/stebo/anaconda3/lib/python3.7/site-packages/andi/diffusion_models.py:85: RuntimeWarning: overflow encountered in power\n",
      "  dt = (1-np.random.rand(T))**(-1/sigma)\n"
     ]
    }
   ],
   "source": [
    "bb={}\n",
    "cc={}\n",
    "cl=[750]\n",
    "j=0\n",
    "for i in cl:\n",
    "    X1, Y1, X2, Y2, X3, Y3 = AD.andi_dataset(N = 50000, tasks = 2, dimensions = 1,\n",
    "                                             min_T = i, max_T = i+1, save_dataset=True, path_datasets=str(i)+'multi')\n",
    "    bb[i]=X2[0]\n",
    "    cc[i]=Y2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "ccm={}\n",
    "for i in cl:\n",
    "    ccm[i]=np.zeros((len(cc[i]),5))\n",
    "    print(ccm[i])\n",
    "    print(ccm[i][j][2])\n",
    "    for j in range(len(cc[i])):\n",
    "        ccm[i][j][int(cc[i][j])]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traj length= 750 batch size= 32 \n",
      "\n",
      "n initial= 0 gap= 0\n",
      "warning!! Overlapping trajectories. gap= 0 trajectory length= 750 final_point= 750 data length 750\n",
      "traj length= 750 batch size= 32 \n",
      "\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/7\n",
      "40000/40000 [==============================] - 988s 25ms/step - loss: 0.2012 - accuracy: 0.9076 - val_loss: 0.1758 - val_accuracy: 0.9203\n",
      "Epoch 2/7\n",
      "40000/40000 [==============================] - 2133s 53ms/step - loss: 0.1808 - accuracy: 0.9186 - val_loss: 0.3767 - val_accuracy: 0.8174\n",
      "Epoch 3/7\n",
      "40000/40000 [==============================] - 1656s 41ms/step - loss: 0.2235 - accuracy: 0.8973 - val_loss: 0.1933 - val_accuracy: 0.9125\n",
      "Epoch 4/7\n",
      "40000/40000 [==============================] - 951s 24ms/step - loss: 0.1796 - accuracy: 0.9178 - val_loss: 0.1693 - val_accuracy: 0.9211\n",
      "Epoch 5/7\n",
      "40000/40000 [==============================] - 927s 23ms/step - loss: 0.1675 - accuracy: 0.9243 - val_loss: 0.1537 - val_accuracy: 0.9300\n",
      "Epoch 6/7\n",
      "40000/40000 [==============================] - 925s 23ms/step - loss: 0.1590 - accuracy: 0.9279 - val_loss: 0.1551 - val_accuracy: 0.9316\n",
      "Epoch 7/7\n",
      "40000/40000 [==============================] - 1003s 25ms/step - loss: 0.1537 - accuracy: 0.9302 - val_loss: 0.1549 - val_accuracy: 0.9313\n",
      "traj length= 750 batch size= 128 \n",
      "\n",
      "n initial= 0 gap= 0\n",
      "warning!! Overlapping trajectories. gap= 0 trajectory length= 750 final_point= 750 data length 750\n",
      "traj length= 750 batch size= 128 \n",
      "\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/7\n",
      "40000/40000 [==============================] - 517s 13ms/step - loss: 0.1397 - accuracy: 0.9375 - val_loss: 0.1390 - val_accuracy: 0.9377\n",
      "Epoch 2/7\n",
      "40000/40000 [==============================] - 518s 13ms/step - loss: 0.1360 - accuracy: 0.9390 - val_loss: 0.1366 - val_accuracy: 0.9390\n",
      "Epoch 3/7\n",
      "40000/40000 [==============================] - 499s 12ms/step - loss: 0.1354 - accuracy: 0.9397 - val_loss: 0.1353 - val_accuracy: 0.9401\n",
      "Epoch 4/7\n",
      "40000/40000 [==============================] - 558s 14ms/step - loss: 0.1344 - accuracy: 0.9399 - val_loss: 0.1321 - val_accuracy: 0.9416\n",
      "Epoch 5/7\n",
      "40000/40000 [==============================] - 554s 14ms/step - loss: 0.1315 - accuracy: 0.9417 - val_loss: 0.1332 - val_accuracy: 0.9416\n",
      "Epoch 6/7\n",
      "40000/40000 [==============================] - 565s 14ms/step - loss: 0.1301 - accuracy: 0.9423 - val_loss: 0.1325 - val_accuracy: 0.9408\n",
      "Epoch 7/7\n",
      "40000/40000 [==============================] - 575s 14ms/step - loss: 0.1290 - accuracy: 0.9424 - val_loss: 0.1341 - val_accuracy: 0.9410\n"
     ]
    }
   ],
   "source": [
    "for batch_size in [32,128]:#[32, 128]:\n",
    "    j=0\n",
    "   \n",
    "    for i in [750]:\n",
    "    \n",
    "        print('traj length=',i,'batch size=', batch_size,'\\n')\n",
    "\n",
    "        test_tim_step=np.arange(i)\n",
    "        show_time_coll=np.tile(test_tim_step,(len(bb[i]),1))\n",
    "        data_show,label_show,traj_show,times_show=data_split(np.asarray(bb[i]),\n",
    "                                                             show_time_coll,labels=np.asarray(ccm[i]),\n",
    "                                                             start_row=0,num_row=len(bb[i]),traj_len=i,n_in=0,\n",
    "                                                             n_samples=1,p_p=1,hmin=0,hmax=2,\n",
    "                                                             limith=False,normalization=True)\n",
    "\n",
    "        print('traj length=',i,'batch size=', batch_size,'\\n')\n",
    "        history_classi_norm_750 = model_classi_norm_750.fit(traj_show.reshape(len(traj_show),i,1), \n",
    "                        label_show,validation_split=0.2,\n",
    "                        epochs=10-int(i/200), \n",
    "                        batch_size=batch_size,\n",
    "                        shuffle=True)\n",
    "    #                     ,validation_data=(data_val, \n",
    "    #                     label_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traj length= 750 batch size= 256 \n",
      "\n",
      "n initial= 0 gap= 0\n",
      "warning!! Overlapping trajectories. gap= 0 trajectory length= 750 final_point= 750 data length 750\n",
      "traj length= 750 batch size= 256 \n",
      "\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/7\n",
      "40000/40000 [==============================] - 462s 12ms/step - loss: 0.1242 - accuracy: 0.9447 - val_loss: 0.1299 - val_accuracy: 0.9425\n",
      "Epoch 2/7\n",
      "40000/40000 [==============================] - 467s 12ms/step - loss: 0.1227 - accuracy: 0.9460 - val_loss: 0.1260 - val_accuracy: 0.9435\n",
      "Epoch 3/7\n",
      "40000/40000 [==============================] - 436s 11ms/step - loss: 0.1212 - accuracy: 0.9462 - val_loss: 0.1263 - val_accuracy: 0.9451\n",
      "Epoch 4/7\n",
      "40000/40000 [==============================] - 475s 12ms/step - loss: 0.1203 - accuracy: 0.9472 - val_loss: 0.1252 - val_accuracy: 0.9452\n",
      "Epoch 5/7\n",
      "40000/40000 [==============================] - 490s 12ms/step - loss: 0.1202 - accuracy: 0.9466 - val_loss: 0.1326 - val_accuracy: 0.9410\n",
      "Epoch 6/7\n",
      "40000/40000 [==============================] - 508s 13ms/step - loss: 0.1201 - accuracy: 0.9472 - val_loss: 0.1274 - val_accuracy: 0.9452\n",
      "Epoch 7/7\n",
      "40000/40000 [==============================] - 397s 10ms/step - loss: 0.1184 - accuracy: 0.9479 - val_loss: 0.1247 - val_accuracy: 0.9453\n"
     ]
    }
   ],
   "source": [
    "for batch_size in [256]:#[32, 128]:\n",
    "    j=0\n",
    "   \n",
    "    for i in [750]:\n",
    "    \n",
    "        print('traj length=',i,'batch size=', batch_size,'\\n')\n",
    "\n",
    "        test_tim_step=np.arange(i)\n",
    "        show_time_coll=np.tile(test_tim_step,(len(bb[i]),1))\n",
    "        data_show,label_show,traj_show,times_show=data_split(np.asarray(bb[i]),\n",
    "                                                             show_time_coll,labels=np.asarray(ccm[i]),\n",
    "                                                             start_row=0,num_row=len(bb[i]),traj_len=i,n_in=0,\n",
    "                                                             n_samples=1,p_p=1,hmin=0,hmax=2,\n",
    "                                                             limith=False,normalization=True)\n",
    "\n",
    "        print('traj length=',i,'batch size=', batch_size,'\\n')\n",
    "        history_classi_norm_750 = model_classi_norm_750.fit(traj_show.reshape(len(traj_show),i,1), \n",
    "                        label_show,validation_split=0.2,\n",
    "                        epochs=10-int(i/200), \n",
    "                        batch_size=batch_size,\n",
    "                        shuffle=True)\n",
    "    #                     ,validation_data=(data_val, \n",
    "    #                     label_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_classi_norm_750.save('task2_1d_classi_norm_750.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine predictions of different nets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_classi_norm_chi = load_model('task2_1d_classi_norm_chi.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_classi_norm_750 = load_model('task2_1d_classi_norm_750.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_classi_norm_100 = load_model('task2_1d_classi_norm_100.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_model=[model_classi_norm_100, model_classi_norm_chi ,model_classi_norm_750]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "trajs_from_files = csv.reader(open('validation_for_scoring/task2.txt','r'), delimiter=';', \n",
    "                                        lineterminator='\\n',quoting=csv.QUOTE_NONNUMERIC)\n",
    "validation = [[],[],[]]\n",
    "for trajs in enumerate(trajs_from_files):\n",
    "    validation[int(trajs[1][0])-1].append(trajs[1][1:])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=[]\n",
    "\n",
    "for traj in validation[0]:\n",
    "    traj=(traj-np.mean(traj))/np.std(traj)\n",
    "    #print(np.mean(traj),np.std(traj))\n",
    "    predictions.append(model_classi_norm_chi.predict(np.asarray(traj).reshape(1,len(traj),1)).flatten())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_to_txt = np.ones((len(predictions), 6))\n",
    "for i in range(len(predictions)):\n",
    "    for j in range(5):\n",
    "        \n",
    "        pred_to_txt[i, j+1] = predictions[i][j]\n",
    "\n",
    "np.savetxt('task2.txt', pred_to_txt.astype(float), fmt = '%1.5f', delimiter = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combining different models according to traj length\n",
    "predictions_comb=[]\n",
    "\n",
    "for traj in validation[0]:\n",
    "    traj=(traj-np.mean(traj))/np.std(traj)\n",
    "    jj=len(traj)\n",
    "    k=int(jj/334)\n",
    "   # print(len(traj),k)\n",
    "    \n",
    "    pr_b=meta_model[k].predict(np.asarray(traj).reshape(1,len(traj),1)).flatten()\n",
    "    if ((len(traj)-k*334>167)and(k<2)):\n",
    "    #    print(\"combine!\",len(traj),k,len(traj)-k*334)\n",
    "        pr_2b=meta_model[k+1].predict(np.asarray(traj).reshape(1,len(traj),1)).flatten()\n",
    "        pr_b=(pr_b+pr_2b)/2\n",
    "    predictions_comb.append(pr_b)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_to_txt = np.ones((len(predictions_comb), 6))\n",
    "for i in range(len(predictions_comb)):\n",
    "    for j in range(5):\n",
    "        \n",
    "        pred_to_txt[i, j+1] = predictions_comb[i][j]\n",
    "\n",
    "np.savetxt('task2_comb.txt', pred_to_txt.astype(float), fmt = '%1.5f', delimiter = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
