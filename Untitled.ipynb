{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a dataset for task(s) 1 and dimension(s) 1.\n",
      "Generating dataset for dimension 1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aykut\\Anaconda3\\lib\\site-packages\\fbm\\fbm.py:172: UserWarning: Combination of increments n and Hurst value H invalid for Davies-Harte method. Reverting to Hosking method. Occurs when n is small and Hurst is close to 1. \n",
      "  \"Combination of increments n and Hurst value H \"\n",
      "C:\\Users\\Aykut\\Anaconda3\\lib\\site-packages\\andi\\diffusion_models.py:85: RuntimeWarning: overflow encountered in power\n",
      "  dt = (1-np.random.rand(T))**(-1/sigma)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a dataset for task(s) 1 and dimension(s) 1.\n",
      "Generating dataset for dimension 1.\n",
      "Creating a dataset for task(s) 1 and dimension(s) 1.\n",
      "Generating dataset for dimension 1.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, None, 250)         255000    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 50)                60200     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 315,251\n",
      "Trainable params: 315,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 90000 samples, validate on 10000 samples\n",
      "90000/90000 [==============================] - 1543s 17ms/sample - loss: 0.2038 - mae: 0.3515 - val_loss: 0.1727 - val_mae: 0.3122\n",
      "Train on 90000 samples, validate on 10000 samples\n",
      " 2336/90000 [..............................] - ETA: 24:20 - loss: 0.1856 - mae: 0.3248"
     ]
    }
   ],
   "source": [
    "import andi\n",
    "import numpy as np\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras import losses, metrics\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import SimpleRNN\n",
    "from tensorflow.keras.layers import LSTM\n",
    "\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Bidirectional\n",
    "from tensorflow.keras.models import load_model\n",
    "import os\n",
    "AD = andi.andi_datasets()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "i = 425\n",
    "N = 100000\n",
    "dimension = 1\n",
    "X1, Y1, Z, Z, Z, Z = AD.andi_dataset(N = N, tasks = 1, dimensions = dimension,\n",
    "                                             min_T = i, max_T = i+1)\n",
    "\n",
    "X2, Y2, Z, Z, Z, Z = AD.andi_dataset(N = N, tasks = 1, dimensions = dimension,\n",
    "                                             min_T = i, max_T = i+1)\n",
    "\n",
    "X3, Y3, Z, Z, Z, Z = AD.andi_dataset(N = N, tasks = 1, dimensions = dimension,\n",
    "                                             min_T = i, max_T = i+1)\n",
    "\n",
    "X1[0] = np.diff(X1[0],axis=1)\n",
    "X2[0] = np.diff(X2[0],axis=1)\n",
    "X3[0] = np.diff(X3[0],axis=1)\n",
    "\n",
    "data_tot=X1[0]\n",
    "data_norm1 = np.array(( data_tot - np.mean(data_tot, axis=1).reshape(len(data_tot),1) ) / np.std(data_tot,axis=1).reshape(len(data_tot),1))\n",
    "data_tot=X2[0]\n",
    "data_norm2 = np.array(( data_tot - np.mean(data_tot, axis=1).reshape(len(data_tot),1) ) / np.std(data_tot,axis=1).reshape(len(data_tot),1))\n",
    "data_tot=X3[0]\n",
    "data_norm3 = np.array(( data_tot - np.mean(data_tot, axis=1).reshape(len(data_tot),1) ) / np.std(data_tot,axis=1).reshape(len(data_tot),1))\n",
    "\n",
    "\n",
    "Y1 = np.array(Y1[0])\n",
    "Y2 = np.array(Y2[0])\n",
    "Y3 = np.array(Y3[0])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Building the network\n",
    "model_norm_long = Sequential()\n",
    "#first layer: LSTM of dimension 64\n",
    "model_norm_long.add(LSTM(250,\n",
    "                return_sequences=True,\n",
    "                recurrent_dropout=0.2,\n",
    "                input_shape=(None, 4)\n",
    "                ))\n",
    "\n",
    "model_norm_long.add(LSTM(50,\n",
    "                    dropout=0,\n",
    "                    ))\n",
    "\n",
    "#Last layer, fully connected\n",
    "model_norm_long.add(Dense(1))\n",
    "model_norm_long.compile(optimizer='adam',\n",
    "                loss='mse', \n",
    "                metrics=['mae'])\n",
    "\n",
    "#Printing a summary of the built network\n",
    "model_norm_long.summary()\n",
    "\n",
    "\n",
    "for n in range(10):\n",
    "    \n",
    "    for batch_size in [32, 128, 512, 2048,]:\n",
    "        \n",
    "        for repeat in range(5):\n",
    "            traj_show = data_norm1\n",
    "            label_show = Y1\n",
    "            history_norm_long = model_norm_long.fit(traj_show.reshape(len(traj_show),int(i/4),4), \n",
    "                                    label_show, \n",
    "                                    epochs=1, \n",
    "                                    batch_size=batch_size,\n",
    "                                    validation_split=0.1,\n",
    "                                    shuffle=True,\n",
    "                                    )\n",
    "            traj_show = data_norm2\n",
    "            label_show = Y2\n",
    "            history_norm_long = model_norm_long.fit(traj_show.reshape(len(traj_show),int(i/4),4), \n",
    "                                    label_show, \n",
    "                                    epochs=1, \n",
    "                                    batch_size=batch_size,\n",
    "                                    validation_split=0.1,\n",
    "                                    shuffle=True,\n",
    "                                    )\n",
    "            traj_show = data_norm3\n",
    "            label_show = Y3\n",
    "            history_norm_long = model_norm_long.fit(traj_show.reshape(len(traj_show),int(i/4),4), \n",
    "                                    label_show, \n",
    "                                    epochs=1, \n",
    "                                    batch_size=batch_size,\n",
    "                                    validation_split=0.1,\n",
    "                                    shuffle=True,\n",
    "                                    )\n",
    "            model_norm_long.save('checkpoint.h5')\n",
    "           \n",
    "        \n",
    "model_norm_long.save('Model_1D_recdout_' + str(i) + '.h5')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
