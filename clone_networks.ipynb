{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, None, 250)         256000    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 50)                60200     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 316,251\n",
      "Trainable params: 316,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import andi\n",
    "import numpy as np\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras import losses, metrics\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import SimpleRNN\n",
    "from tensorflow.keras.layers import LSTM\n",
    "\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Bidirectional\n",
    "from tensorflow.keras.models import load_model\n",
    "import os\n",
    "AD = andi.andi_datasets()\n",
    "\n",
    "\n",
    "\n",
    "#LTSM network for learning  the Hurst exponet H, Normalized trajectories!!!\n",
    "\n",
    "#Building the network\n",
    "model_norm_long = Sequential()\n",
    "#first layer: LSTM of dimension 64\n",
    "model_norm_long.add(LSTM(250,\n",
    "                return_sequences=True,\n",
    "                dropout=0,\n",
    "                input_shape=(None, 5)\n",
    "                ))\n",
    "\n",
    "model_norm_long.add(LSTM(50,\n",
    "                dropout=0))\n",
    "\n",
    "#Last layer, fully connected\n",
    "model_norm_long.add(Dense(1))\n",
    "model_norm_long.compile(optimizer='adam',\n",
    "                loss='mse', \n",
    "                metrics=['mae'])\n",
    "\n",
    "#Printing a summary of the built network\n",
    "model_norm_long.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a dataset for task(s) 1 and dimension(s) 1.\n",
      "Creating a dataset for task(s) 1 and dimension(s) 1.\n",
      "Creating a dataset for task(s) 1 and dimension(s) 1.\n"
     ]
    }
   ],
   "source": [
    "i = 425\n",
    "N = 100000\n",
    "X1, Y1, X2, Z, X3, Z = AD.andi_dataset(N = N, tasks = 1, dimensions = 1,\n",
    "                                             min_T = i, max_T = i+1, load_dataset=True, path_datasets=str(i)+'master1')\n",
    "\n",
    "X2, Y2, Z, Z, X3, Z = AD.andi_dataset(N = N, tasks = 1, dimensions = 1,\n",
    "                                             min_T = i, max_T = i+1, load_dataset=True, path_datasets=str(i)+'master2')\n",
    "\n",
    "X3, Y3, Z, Z, Z, Z = AD.andi_dataset(N = N, tasks = 1, dimensions = 1,\n",
    "                                             min_T = i, max_T = i+1, load_dataset=True, path_datasets=str(i)+'master3')\n",
    "\n",
    "X1[0] = np.diff(X1[0],axis=1)\n",
    "X2[0] = np.diff(X2[0],axis=1)\n",
    "X3[0] = np.diff(X3[0],axis=1)\n",
    "\n",
    "data_tot=X1[0]\n",
    "data_norm1 = np.array(( data_tot - np.mean(data_tot, axis=1).reshape(len(data_tot),1) ) / np.std(data_tot,axis=1).reshape(len(data_tot),1))\n",
    "data_tot=X2[0]\n",
    "data_norm2 = np.array(( data_tot - np.mean(data_tot, axis=1).reshape(len(data_tot),1) ) / np.std(data_tot,axis=1).reshape(len(data_tot),1))\n",
    "data_tot=X3[0]\n",
    "data_norm3 = np.array(( data_tot - np.mean(data_tot, axis=1).reshape(len(data_tot),1) ) / np.std(data_tot,axis=1).reshape(len(data_tot),1))\n",
    "\n",
    "\n",
    "Y1 = np.array(Y1[0])\n",
    "Y2 = np.array(Y2[0])\n",
    "Y3 = np.array(Y3[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (None, None, 250)         255000    \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 50)                60200     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 315,251\n",
      "Trainable params: 315,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Building the network\n",
    "model_norm_long = Sequential()\n",
    "#first layer: LSTM of dimension 64\n",
    "model_norm_long.add(LSTM(250,\n",
    "                return_sequences=True,\n",
    "                recurrent_dropout=0.2,\n",
    "                input_shape=(None, 4)\n",
    "                ))\n",
    "\n",
    "model_norm_long.add(LSTM(50,\n",
    "                    dropout=0,\n",
    "                    recurrent_dropout=0.2,\n",
    "                    ))\n",
    "\n",
    "#Last layer, fully connected\n",
    "model_norm_long.add(Dense(1))\n",
    "model_norm_long.compile(optimizer='adam',\n",
    "                loss='mse', \n",
    "                metrics=['mae'])\n",
    "\n",
    "#Printing a summary of the built network\n",
    "model_norm_long.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model_norm_long = load_model('checkpoint.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 90000 samples, validate on 10000 samples\n",
      "53536/90000 [================>.............] - ETA: 4:15 - loss: 0.1369 - mae: 0.2840"
     ]
    }
   ],
   "source": [
    "for n in range(10):\n",
    "\n",
    "    \n",
    "    for batch_size in [32, 128, 512, 2048,]:\n",
    "        \n",
    "        for repeat in range(5):\n",
    "            traj_show = data_norm1\n",
    "            label_show = Y1\n",
    "            history_norm_long = model_norm_long.fit(traj_show.reshape(len(traj_show),int(i/4),4), \n",
    "                                    label_show, \n",
    "                                    epochs=1, \n",
    "                                    batch_size=batch_size,\n",
    "                                    validation_split=0.1,\n",
    "                                    shuffle=True,\n",
    "                                    )\n",
    "            traj_show = data_norm2\n",
    "            label_show = Y2\n",
    "            history_norm_long = model_norm_long.fit(traj_show.reshape(len(traj_show),int(i/4),4), \n",
    "                                    label_show, \n",
    "                                    epochs=1, \n",
    "                                    batch_size=batch_size,\n",
    "                                    validation_split=0.1,\n",
    "                                    shuffle=True,\n",
    "                                    )\n",
    "            traj_show = data_norm3\n",
    "            label_show = Y3\n",
    "            history_norm_long = model_norm_long.fit(traj_show.reshape(len(traj_show),int(i/4),4), \n",
    "                                    label_show, \n",
    "                                    epochs=1, \n",
    "                                    batch_size=batch_size,\n",
    "                                    validation_split=0.1,\n",
    "                                    shuffle=True,\n",
    "                                    )\n",
    "            model_norm_long.save('checkpoint.h5')\n",
    "    model_norm_long.save('Clone_425_' + str(4) +'.h5')\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sci\n",
    "sci.savemat('125trial.mat',{'traj': traj_show, 'label': label_show})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
